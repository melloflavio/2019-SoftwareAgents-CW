{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import json\n",
    "# import csv\n",
    "# import collections\n",
    "import pydash as _\n",
    "import itertools\n",
    "from enum import Enum, unique\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Board movement\n",
    "General board movement functions and definitions.\n",
    "The board matrix is framed and padded with `NaN` for easier manipulation of movements without the need to take into account out of bounds indexes.\n",
    "The location map object maps string indexes to board coordinates. Given that the board has only 6 playable spaces, any possible board configuration can be translated into a single 6 character string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board & Movement constants\n",
    "BOARD_SIZE = (5,7) # NxN board\n",
    "BOARD_WIDTH = BOARD_SIZE[0]\n",
    "BOARD_HEIGHT = BOARD_SIZE[1]\n",
    "\n",
    "# LOCATION_MAP = {\n",
    "#     0: (1,2),\n",
    "#     1: (2,1),\n",
    "#     2: (2,2),\n",
    "#     3: (2,3),\n",
    "#     4: (3,2),\n",
    "#     5: (4,2),\n",
    "#     6: (5,2),\n",
    "# }\n",
    "LOCATION_MAP = {\n",
    "    0: (2,1),\n",
    "    1: (1,2),\n",
    "    2: (2,2),\n",
    "    3: (3,2),\n",
    "    4: (2,3),\n",
    "    5: (2,4),\n",
    "    6: (2,5),\n",
    "}\n",
    "\n",
    "@unique\n",
    "class ACTION(Enum):\n",
    "    UP = 1\n",
    "    RIGHT = 2\n",
    "    DOWN = 3\n",
    "    LEFT = 4\n",
    "    STAY = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Board <=> State String transitions \n",
    "Calculating and performing movements is easier done with a matrix than an encoded string, thus the project relies on translating state strings into boards back and forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty board: \n",
      "[[nan nan nan nan nan nan nan]\n",
      " [nan nan  0. nan nan nan nan]\n",
      " [nan  0.  0.  0.  0.  0. nan]\n",
      " [nan nan  0. nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan]]\n",
      "\n",
      "\n",
      "Board for state 0000321: \n",
      "[[nan nan nan nan nan nan nan]\n",
      " [nan nan  0. nan nan nan nan]\n",
      " [nan  0.  0.  3.  2.  1. nan]\n",
      " [nan nan  0. nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan]]\n",
      "\n",
      "\n",
      "State for board: \n",
      "[[nan nan nan nan nan nan nan]\n",
      " [nan nan  0. nan nan nan nan]\n",
      " [nan  1.  0.  0.  0.  0. nan]\n",
      " [nan nan  0. nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan]] \n",
      "\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "def get_empty_board():\n",
    "    empty_board = np.full(BOARD_SIZE, np.nan)\n",
    "    for loc_tuple in LOCATION_MAP.values():\n",
    "        empty_board[loc_tuple] = 0\n",
    "    return empty_board\n",
    "\n",
    "print('Empty board: \\n{}'.format(get_empty_board()))\n",
    "\n",
    "def get_board_for_state_string(state_string):\n",
    "    if(len(state_string) != len(LOCATION_MAP.values())):\n",
    "        raise ValueError('StateString size if invalid')\n",
    "    board = np.full(BOARD_SIZE, np.nan) # Start with empty board\n",
    "    state_tokens = list(state_string)\n",
    "    for location_idx, value in enumerate(state_tokens):\n",
    "        location_tuple = LOCATION_MAP[location_idx]\n",
    "        board[location_tuple] = value\n",
    "        \n",
    "    return board\n",
    "\n",
    "test_input = '0000321'\n",
    "print('\\n\\nBoard for state {}: \\n{}'.format(test_input, get_board_for_state_string(test_input)))\n",
    "\n",
    "\n",
    "def get_state_string_for_board(board):\n",
    "    \n",
    "    state_tokens = [np.nan]*len(LOCATION_MAP.values())\n",
    "    for (location_idx, location_tuple) in LOCATION_MAP.items():\n",
    "        state_tokens[location_idx] = str(int(board[location_tuple]))\n",
    "    \n",
    "    state_string = ''.join(state_tokens)\n",
    "    return state_string\n",
    "\n",
    "\n",
    "test_input = np.array([[np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "                       [np.nan, np.nan,   0.,   np.nan, np.nan, np.nan, np.nan],\n",
    "                       [np.nan,    1.,    0.,     0.,     0.,     0.,   np.nan],\n",
    "                       [np.nan, np.nan,   0.,   np.nan, np.nan, np.nan, np.nan],\n",
    "                       [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]])\n",
    "print('\\n\\nState for board: \\n{} \\n\\n{}'.format(test_input, get_state_string_for_board(test_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State Transition & Reward\n",
    "\n",
    "By leveraging the state string to board transformations, we are able to calculate the possible movements for a given agent & execute said moves in a simple maner. Agents are able to move in the cardinal directions to adjacent open spaces. As an alternative, the agent always has the option of staying in place. All combined, there are 5 possible valid movements an agent can make, but depending on its position, only a subset may be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal State: 0000001\n",
      "Random State: 1000000\n",
      "Possible States:\n",
      "  ['0010000', '0000100', '1000000', '0001000', '0000001', '0000010', '0100000']\n"
     ]
    }
   ],
   "source": [
    "# Terminal States manually selected for 1,2 and 3 agent variations\n",
    "def get_terminal_state(num_agents):\n",
    "    return   '0000001' if num_agents is 1 \\\n",
    "        else '0000021' if num_agents is 2 \\\n",
    "        else '0000321' if num_agents is 3 \\\n",
    "        else ''\n",
    "print('Terminal State: {}'.format(get_terminal_state(1)))\n",
    "\n",
    "\n",
    "def get_random_state(num_agents):\n",
    "    state = get_terminal_state(num_agents) # Start with terminal state\n",
    "    state = list(state) # Shuffle requires an array as input\n",
    "    random.shuffle(state)\n",
    "    state = ''.join(state) # Back into a single string\n",
    "    return state\n",
    "\n",
    "print('Random State: {}'.format(get_random_state(1)))\n",
    "\n",
    "# Returns all possible states that can be reached given a number of agents in the board\n",
    "def get_possible_states(num_agents):\n",
    "    terminal_state = get_terminal_state(num_agents)\n",
    "    \n",
    "    possible_states = set(itertools.permutations(terminal_state)) # All UNIQUE permutations\n",
    "    possible_states = [''.join(state) for state in possible_states] # itertools returns arrays of chars, joining into complete strings\n",
    "    return possible_states\n",
    "\n",
    "print('Possible States:\\n  {}'.format(get_possible_states(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move from State: 1000000 + ACTION.DOWN => Resulting state: 1000000\n",
      "Available destinations from 1000000: ['0010000', '1000000']\n"
     ]
    }
   ],
   "source": [
    "# If the destination is not valid (i.e. not an open space), the function returns the current position as next_state\n",
    "\n",
    "def move_agent(state_string, agent_id, action):\n",
    "    agent_location = state_string.find(str(agent_id))\n",
    "    (row, col) = LOCATION_MAP[agent_location]\n",
    "    board = get_board_for_state_string(state_string)\n",
    "    if (action == ACTION.UP and board[(row-1,col)] == 0):\n",
    "        board[(row-1,col)] = agent_id\n",
    "        board[(row,col)] = 0\n",
    "        return get_state_string_for_board(board)\n",
    "    elif (action == ACTION.RIGHT and board[(row,col+1)] == 0):\n",
    "        board[(row,col+1)] = agent_id\n",
    "        board[(row,col)] = 0\n",
    "        return get_state_string_for_board(board)\n",
    "    elif (action == ACTION.DOWN and board[(row+1,col)] == 0):\n",
    "        board[(row+1,col)] = agent_id\n",
    "        board[(row,col)] = 0\n",
    "        return get_state_string_for_board(board)\n",
    "    elif (action == ACTION.LEFT and board[(row,col-1)] == 0):\n",
    "        board[(row,col-1)] = agent_id\n",
    "        board[(row,col)] = 0\n",
    "        return get_state_string_for_board(board)\n",
    "    else: # Either ACTION.STAY or unnable to execute move\n",
    "        return get_state_string_for_board(board)\n",
    "\n",
    "print('Move from State: {} + {} => Resulting state: {}'.format('1000000', ACTION.DOWN, move_agent('1000000', 1, ACTION.DOWN)))\n",
    "\n",
    "def get_available_moves(state_string, agent_id):\n",
    "    moves = [move_agent(state_string, agent_id, action) for action in ACTION]\n",
    "    unique_moves = list(set(moves))\n",
    "    return unique_moves\n",
    "\n",
    "print('Available destinations from 1000000: {}'.format(get_available_moves('1000000', 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Matrix \n",
    "The transition matrix maps origin states (rows) into destination states (columns). Thus it is a NxN matrix, N being the number of possible states. Invalid transitions are represented as `NaN` values for a given tuple, while possible transitions are represented as `0`.\n",
    "\n",
    "Having the default value being `0` also serves a purpose of reutilizing the generated transition matrix as the basis for the R matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0010000</th>\n",
       "      <th>0000100</th>\n",
       "      <th>1000000</th>\n",
       "      <th>0001000</th>\n",
       "      <th>0000001</th>\n",
       "      <th>0000010</th>\n",
       "      <th>0100000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0010000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000010</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0100000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0010000  0000100  1000000  0001000  0000001  0000010  0100000\n",
       "state                                                                 \n",
       "0010000      0.0      0.0      0.0      0.0      NaN      NaN      0.0\n",
       "0000100      0.0      0.0      NaN      NaN      NaN      0.0      NaN\n",
       "1000000      0.0      NaN      0.0      NaN      NaN      NaN      NaN\n",
       "0001000      0.0      NaN      NaN      0.0      NaN      NaN      NaN\n",
       "0000001      NaN      NaN      NaN      NaN      0.0      0.0      NaN\n",
       "0000010      NaN      0.0      NaN      NaN      0.0      0.0      NaN\n",
       "0100000      0.0      NaN      NaN      NaN      NaN      NaN      0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_transition_matrix(agent_id, num_agents):\n",
    "    if (agent_id > num_agents):\n",
    "        raise ValueError('Invalid Agent_Id')\n",
    "    possible_states = get_possible_states(num_agents)\n",
    "    \n",
    "#   Generate blank NxN Dataframe with all possible states as rows & columns\n",
    "    df = pd.DataFrame({'state': possible_states,\n",
    "                        **{state: np.nan for state in possible_states}\n",
    "                       })\n",
    "    df.set_index('state', inplace=True)\n",
    "    \n",
    "#   Fill in possible transitions with 0\n",
    "    for state_string in possible_states:\n",
    "        available_moves = get_available_moves(state_string, agent_id)\n",
    "        df.loc[state_string, available_moves] = 0\n",
    "    \n",
    "    return df\n",
    "    \n",
    "generate_transition_matrix(agent_id=1, num_agents=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-Matrix and reward function\n",
    "Given that each agent has slightly different transition functions, the reward function also difrs by agent. Although the same general rule applies. Agents are awarded 100 points for any transition that takes them to the desired terminal state, and they are penalized 100 points for any transition that takes them away from it. Any other transition is given no reward.\n",
    "\n",
    "For generating the R-matrix, the program simply starts with the transition matrix, and fills the relevant transitions with either `-100` or `100` accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0010000</th>\n",
       "      <th>0000100</th>\n",
       "      <th>1000000</th>\n",
       "      <th>0001000</th>\n",
       "      <th>0000001</th>\n",
       "      <th>0000010</th>\n",
       "      <th>0100000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0010000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000010</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0100000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0010000  0000100  1000000  0001000  0000001  0000010  0100000\n",
       "state                                                                 \n",
       "0010000      0.0      0.0      0.0      0.0      NaN      NaN      0.0\n",
       "0000100      0.0      0.0      NaN      NaN      NaN      0.0      NaN\n",
       "1000000      0.0      NaN      0.0      NaN      NaN      NaN      NaN\n",
       "0001000      0.0      NaN      NaN      0.0      NaN      NaN      NaN\n",
       "0000001      NaN      NaN      NaN      NaN    100.0   -100.0      NaN\n",
       "0000010      NaN      0.0      NaN      NaN    100.0      0.0      NaN\n",
       "0100000      0.0      NaN      NaN      NaN      NaN      NaN      0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_reward_matrix(agent_id, num_agents):\n",
    "    reward = EXPERIMENT['return']\n",
    "    penalty = EXPERIMENT['penalty']\n",
    "#     Start with Transistion Matrix which already has 0 for all transitions\n",
    "    reward_matrix = generate_transition_matrix(agent_id, num_agents)\n",
    "    \n",
    "#     Set reward at possible transitions to terminal state\n",
    "    terminal_state = get_terminal_state(num_agents)\n",
    "    possible_origins = get_available_moves(terminal_state, agent_id) # Destinations & Origins are symmetric\n",
    "    reward_matrix.loc[terminal_state, possible_origins] = penalty # Moves going out of terminal state are penlized by 100\n",
    "    reward_matrix.loc[possible_origins, terminal_state] = reward # Moves going into terminal state are rewarded 100\n",
    "    return reward_matrix\n",
    "\n",
    "generate_reward_matrix(agent_id=1, num_agents=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1:          0010000  0000100  1000000  0001000  0000001  0000010  0100000\n",
       "  state                                                                 \n",
       "  0010000      0.0      0.0      0.0      0.0      NaN      NaN      0.0\n",
       "  0000100      0.0      0.0      NaN      NaN      NaN      0.0      NaN\n",
       "  1000000      0.0      NaN      0.0      NaN      NaN      NaN      NaN\n",
       "  0001000      0.0      NaN      NaN      0.0      NaN      NaN      NaN\n",
       "  0000001      NaN      NaN      NaN      NaN      0.0      0.0      NaN\n",
       "  0000010      NaN      0.0      NaN      NaN      0.0      0.0      NaN\n",
       "  0100000      0.0      NaN      NaN      NaN      NaN      NaN      0.0},\n",
       " {1:          0010000  0000100  1000000  0001000  0000001  0000010  0100000\n",
       "  state                                                                 \n",
       "  0010000      0.0      0.0      0.0      0.0      NaN      NaN      0.0\n",
       "  0000100      0.0      0.0      NaN      NaN      NaN      0.0      NaN\n",
       "  1000000      0.0      NaN      0.0      NaN      NaN      NaN      NaN\n",
       "  0001000      0.0      NaN      NaN      0.0      NaN      NaN      NaN\n",
       "  0000001      NaN      NaN      NaN      NaN    100.0   -100.0      NaN\n",
       "  0000010      NaN      0.0      NaN      NaN    100.0      0.0      NaN\n",
       "  0100000      0.0      NaN      NaN      NaN      NaN      NaN      0.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_tables(num_agents):\n",
    "    # Each agent has its own Q and R tables\n",
    "    Q = {agent_id: generate_transition_matrix(agent_id, num_agents) for agent_id in get_agent_ids()}\n",
    "    R = {agent_id: generate_reward_matrix(agent_id, num_agents) for agent_id in get_agent_ids()}\n",
    "    return (Q, R)\n",
    "    \n",
    "initialize_tables(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Parameter Setting\n",
    "The learning parameters are defined below as a globally scoped variable to enable ease of access by the methods lying in multiple layers of abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = {\n",
    "    'num_agents': 1,        # ∈ {1,2,3}\n",
    "    'num_episodes': 10000,    # Number of episodes the experiment lasts\n",
    "    'max_steps': 6,       # Max steps per episode\n",
    "    'epsilom': {\n",
    "        'initial_value': 0.999,\n",
    "        'decay_rate_1': 0.999,  # Decay if e >= threshold\n",
    "        'decay_rate_2': 0.99,   # Decay if e < threshold\n",
    "        'decay_rate_threshold': 0.5,\n",
    "    },\n",
    "    'alpha': 0.5, # learning rate\n",
    "    'gamma': 0.5, # dicount factor\n",
    "    'return': 100, # Return for moving into terminal state\n",
    "    'penalty': -100, # Punishment for leaving terminal state\n",
    "}\n",
    "\n",
    "# Helper function to allow for agent id enumeration\n",
    "def get_agent_ids():\n",
    "    return range(1, EXPERIMENT['num_agents']+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Learning Episode\n",
    "Each learning episode starts with a random state. Agents then take turns performing actions, observeing the punishment/reward given by their respective R-Matrix and updating their respective Q-Matrix accordingly.\n",
    "\n",
    "An episode ends when either a predefined number of steps are taken(configurable in the experiment parameters), or the terminal state is reached. One detail that is important to stress is that the terminal state is only considered as reached when every single agent has perfomed an action that results in reaching that state, thus collecting its reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epsilom': 0.5,\n",
       " 'total_steps': 16,\n",
       " 'reward_1': 0.0,\n",
       " 'reward_2': 0.0,\n",
       " 'reward_total': 0.0,\n",
       " 'final_state': '1000002',\n",
       " 'did_reach_terminal': False}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_episode(epsilom):\n",
    "    # Episode strating values    \n",
    "    num_agents = EXPERIMENT['num_agents']\n",
    "    total_reward = 0 \n",
    "    agent_reward = {agent_id: 0 for agent_id in get_agent_ids()}\n",
    "    current_state = get_random_state(num_agents)\n",
    "    state_history = [current_state]\n",
    "    \n",
    "    while(not did_finish_episode(state_history)):\n",
    "        current_agent_id = (len(state_history) % num_agents) + 1 # agent_ids start at 1. Agents take turns performing actions\n",
    "        next_state = choose_next_state(current_state, current_agent_id, epsilom)\n",
    "        \n",
    "        earned_return = calculate_earned_return(current_state, next_state, current_agent_id) # Determine return from R matrix for the agent taking action\n",
    "        update_q_matrix(current_state, next_state, current_agent_id, earned_return) # Update Q Matrix for the agent taking action\n",
    "        \n",
    "        # Update values for next loop pass\n",
    "        state_history.append(next_state)\n",
    "        current_state = next_state\n",
    "        agent_reward[current_agent_id] += earned_return\n",
    "        total_reward += earned_return\n",
    "        \n",
    "    did_reach_terminal = state_history[-1] == get_terminal_state(num_agents)\n",
    "    \n",
    "    return ({\n",
    "        'epsilom': epsilom,\n",
    "        'total_steps':len(state_history), \n",
    "        **{('reward_'+str(agent_id)): agent_reward[agent_id] for agent_id in get_agent_ids()},\n",
    "        'reward_total':total_reward,\n",
    "        'final_state': current_state, \n",
    "        'did_reach_terminal':did_reach_terminal\n",
    "    })\n",
    "\n",
    "def did_finish_episode(state_history):\n",
    "    current_step = len(state_history)\n",
    "    terminal_state = get_terminal_state(EXPERIMENT['num_agents'])\n",
    "    recent_history = state_history[-EXPERIMENT['num_agents']:]     # Ensures terminal state is reached only after ALL agents took one action after reaching it & gained their reward\n",
    "    \n",
    "    if (current_step > 1 and all(state == terminal_state for state in recent_history)):\n",
    "        return True\n",
    "    elif (current_step > EXPERIMENT['max_steps']): # Agent timeout. Finish episode by exhaustion\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "run_episode(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Matrix update\n",
    "\n",
    "\n",
    "After each step, the Q matrix is updated according to the earned return and current Q-Matrix according to the following formula\n",
    "$$Q(s_{t},a_{t}) = Q(s_{t},a_{t}) + α*[r_{t+1}+γ*max_{a} Q(s_{t+1},a_{t+1}) - Q(s_{t},a_{t})]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the RETURN in table R associated with transitioning from current to next state\n",
    "def calculate_earned_return(current_state, next_state, current_agent_id):\n",
    "    current_r = R[current_agent_id] # Get current agent's R-matrix\n",
    "    earned_return = current_r.loc[current_state, next_state]\n",
    "    return earned_return\n",
    "\n",
    "def update_q_matrix(current_state, next_state, current_agent_id, earned_return):\n",
    "    alpha = EXPERIMENT['alpha']\n",
    "    gamma = EXPERIMENT['gamma']\n",
    "    \n",
    "    \n",
    "    current_q = Q[current_agent_id] # Get current agent's Q-matrix\n",
    "    old_expected_return = current_q.loc[current_state, next_state]\n",
    "    \n",
    "    possible_next_moves = get_available_moves(next_state, current_agent_id)\n",
    "    best_expected_reward = max(current_q.loc[next_state, possible_next_moves])\n",
    "    \n",
    "    new_expected_return = old_expected_return + alpha * (earned_return + gamma * best_expected_reward - old_expected_return)\n",
    "    current_q.loc[current_state, next_state] = new_expected_return\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilom update policy\n",
    "The ε-greedy policy determines that the agent is to explore (i.e. take a random action) with ε probability, and exploit (i.e. take the action which has the highest expected return as per the Q-matrix) with (1-ε) probability. A strategy for gradual refinement is to have a gradually decreasing ε value. This means that when there is more uncertainty (i.e. at the beginning of the experiment, when not much is known regarding the environment), the agent takes action randomly to gather feedback and \"understanding\" of the surrounding environment. Gradually, the more the agent knows regarding the environment,less often it takes random actions. This effectively has the result of directing the random exploration to regions surrounding the current action policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_next_state(current_state, current_agent_id, epsilom):    \n",
    "    # exploit\n",
    "    if (random.random() >= epsilom):\n",
    "        current_q = Q[current_agent_id] # Get current agent's Q-matrix\n",
    "        max_expected_rewards = current_q.idxmax(axis=1) # Column index for max value in each row\n",
    "        return max_expected_rewards[current_state]\n",
    "        \n",
    "    # explore\n",
    "    else:\n",
    "        possible_moves = get_available_moves(current_state, current_agent_id)\n",
    "        return random.choice(possible_moves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_epsilom(epsilom):\n",
    "    if (epsilom >= EXPERIMENT['epsilom']['decay_rate_threshold']):\n",
    "        decay_rate = EXPERIMENT['epsilom']['decay_rate_1']\n",
    "    else:\n",
    "        decay_rate = EXPERIMENT['epsilom']['decay_rate_2']\n",
    "    return epsilom * decay_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "\n",
    "An experiment is defined as a collection of learning episodes while using a defined set of parameters. After each learning episode, it's results are stored for later analysis, and the epsilom value is updated according to the epsilom greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00%  10%  20%  30%  40%  50%  60%  70%  80%  90%  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'episode': 0,\n",
       "  'epsilom': 0.9999,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 1,\n",
       "  'epsilom': 0.999890001,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 2,\n",
       "  'epsilom': 0.9998800020999901,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 3,\n",
       "  'epsilom': 0.9998700032999691,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 4,\n",
       "  'epsilom': 0.9998600045999362,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 5,\n",
       "  'epsilom': 0.9998500059998903,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 6,\n",
       "  'epsilom': 0.9998400074998303,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 7,\n",
       "  'epsilom': 0.9998300090997553,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 8,\n",
       "  'epsilom': 0.9998200107996643,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 9,\n",
       "  'epsilom': 0.9998100125995564,\n",
       "  'total_steps': 13,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 10,\n",
       "  'epsilom': 0.9998000144994305,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 11,\n",
       "  'epsilom': 0.9997900164992856,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 12,\n",
       "  'epsilom': 0.9997800185991206,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 13,\n",
       "  'epsilom': 0.9997700207989346,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 14,\n",
       "  'epsilom': 0.9997600230987267,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 15,\n",
       "  'epsilom': 0.9997500254984958,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 16,\n",
       "  'epsilom': 0.9997400279982408,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 17,\n",
       "  'epsilom': 0.9997300305979608,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 18,\n",
       "  'epsilom': 0.9997200332976549,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 19,\n",
       "  'epsilom': 0.999710036097322,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 20,\n",
       "  'epsilom': 0.999700038996961,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 21,\n",
       "  'epsilom': 0.9996900419965711,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 22,\n",
       "  'epsilom': 0.9996800450961512,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 23,\n",
       "  'epsilom': 0.9996700482957003,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 24,\n",
       "  'epsilom': 0.9996600515952173,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 25,\n",
       "  'epsilom': 0.9996500549947014,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 26,\n",
       "  'epsilom': 0.9996400584941515,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 27,\n",
       "  'epsilom': 0.9996300620935666,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 28,\n",
       "  'epsilom': 0.9996200657929457,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 29,\n",
       "  'epsilom': 0.9996100695922878,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 30,\n",
       "  'epsilom': 0.999600073491592,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 31,\n",
       "  'epsilom': 0.999590077490857,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 32,\n",
       "  'epsilom': 0.9995800815900822,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 33,\n",
       "  'epsilom': 0.9995700857892663,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 34,\n",
       "  'epsilom': 0.9995600900884085,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 35,\n",
       "  'epsilom': 0.9995500944875076,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 36,\n",
       "  'epsilom': 0.9995400989865628,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 37,\n",
       "  'epsilom': 0.999530103585573,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 38,\n",
       "  'epsilom': 0.9995201082845372,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 39,\n",
       "  'epsilom': 0.9995101130834544,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 40,\n",
       "  'epsilom': 0.9995001179823236,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 41,\n",
       "  'epsilom': 0.9994901229811438,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 42,\n",
       "  'epsilom': 0.999480128079914,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 43,\n",
       "  'epsilom': 0.9994701332786333,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 44,\n",
       "  'epsilom': 0.9994601385773005,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 45,\n",
       "  'epsilom': 0.9994501439759148,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 46,\n",
       "  'epsilom': 0.9994401494744751,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 47,\n",
       "  'epsilom': 0.9994301550729804,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 48,\n",
       "  'epsilom': 0.9994201607714297,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 49,\n",
       "  'epsilom': 0.9994101665698221,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 50,\n",
       "  'epsilom': 0.9994001724681564,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 51,\n",
       "  'epsilom': 0.9993901784664317,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 52,\n",
       "  'epsilom': 0.9993801845646472,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 53,\n",
       "  'epsilom': 0.9993701907628015,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 54,\n",
       "  'epsilom': 0.999360197060894,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 55,\n",
       "  'epsilom': 0.9993502034589234,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 56,\n",
       "  'epsilom': 0.9993402099568889,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 57,\n",
       "  'epsilom': 0.9993302165547894,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 58,\n",
       "  'epsilom': 0.9993202232526238,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 59,\n",
       "  'epsilom': 0.9993102300503913,\n",
       "  'total_steps': 5,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 60,\n",
       "  'epsilom': 0.9993002369480909,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 61,\n",
       "  'epsilom': 0.9992902439457214,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 62,\n",
       "  'epsilom': 0.999280251043282,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 63,\n",
       "  'epsilom': 0.9992702582407716,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 64,\n",
       "  'epsilom': 0.9992602655381893,\n",
       "  'total_steps': 11,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 65,\n",
       "  'epsilom': 0.9992502729355339,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 66,\n",
       "  'epsilom': 0.9992402804328047,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 67,\n",
       "  'epsilom': 0.9992302880300004,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 68,\n",
       "  'epsilom': 0.9992202957271201,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 69,\n",
       "  'epsilom': 0.9992103035241628,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 70,\n",
       "  'epsilom': 0.9992003114211276,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 71,\n",
       "  'epsilom': 0.9991903194180135,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 72,\n",
       "  'epsilom': 0.9991803275148193,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 73,\n",
       "  'epsilom': 0.9991703357115442,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 74,\n",
       "  'epsilom': 0.9991603440081872,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 75,\n",
       "  'epsilom': 0.9991503524047471,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 76,\n",
       "  'epsilom': 0.9991403609012232,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 77,\n",
       "  'epsilom': 0.9991303694976141,\n",
       "  'total_steps': 13,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 78,\n",
       "  'epsilom': 0.9991203781939192,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 79,\n",
       "  'epsilom': 0.9991103869901373,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 80,\n",
       "  'epsilom': 0.9991003958862674,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 81,\n",
       "  'epsilom': 0.9990904048823086,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 82,\n",
       "  'epsilom': 0.9990804139782599,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 83,\n",
       "  'epsilom': 0.9990704231741201,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 84,\n",
       "  'epsilom': 0.9990604324698884,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 85,\n",
       "  'epsilom': 0.9990504418655638,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 86,\n",
       "  'epsilom': 0.9990404513611452,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 87,\n",
       "  'epsilom': 0.9990304609566316,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 88,\n",
       "  'epsilom': 0.999020470652022,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 89,\n",
       "  'epsilom': 0.9990104804473156,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 90,\n",
       "  'epsilom': 0.9990004903425111,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 91,\n",
       "  'epsilom': 0.9989905003376077,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 92,\n",
       "  'epsilom': 0.9989805104326044,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 93,\n",
       "  'epsilom': 0.9989705206275001,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 94,\n",
       "  'epsilom': 0.9989605309222939,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 95,\n",
       "  'epsilom': 0.9989505413169847,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 96,\n",
       "  'epsilom': 0.9989405518115716,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 97,\n",
       "  'epsilom': 0.9989305624060535,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 98,\n",
       "  'epsilom': 0.9989205731004295,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 99,\n",
       "  'epsilom': 0.9989105838946986,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 100,\n",
       "  'epsilom': 0.9989005947888596,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 101,\n",
       "  'epsilom': 0.9988906057829118,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 102,\n",
       "  'epsilom': 0.998880616876854,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 103,\n",
       "  'epsilom': 0.9988706280706853,\n",
       "  'total_steps': 2,\n",
       "  'reward_1': 0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 104,\n",
       "  'epsilom': 0.9988606393644046,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 105,\n",
       "  'epsilom': 0.998850650758011,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 106,\n",
       "  'epsilom': 0.9988406622515035,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 107,\n",
       "  'epsilom': 0.998830673844881,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 108,\n",
       "  'epsilom': 0.9988206855381426,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 109,\n",
       "  'epsilom': 0.9988106973312872,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 110,\n",
       "  'epsilom': 0.998800709224314,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 111,\n",
       "  'epsilom': 0.9987907212172218,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 112,\n",
       "  'epsilom': 0.9987807333100097,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 113,\n",
       "  'epsilom': 0.9987707455026766,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 114,\n",
       "  'epsilom': 0.9987607577952217,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 115,\n",
       "  'epsilom': 0.9987507701876438,\n",
       "  'total_steps': 15,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 116,\n",
       "  'epsilom': 0.9987407826799419,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 117,\n",
       "  'epsilom': 0.9987307952721152,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 118,\n",
       "  'epsilom': 0.9987208079641625,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 119,\n",
       "  'epsilom': 0.998710820756083,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 120,\n",
       "  'epsilom': 0.9987008336478754,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 121,\n",
       "  'epsilom': 0.998690846639539,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 122,\n",
       "  'epsilom': 0.9986808597310727,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 123,\n",
       "  'epsilom': 0.9986708729224754,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 124,\n",
       "  'epsilom': 0.9986608862137462,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 125,\n",
       "  'epsilom': 0.9986508996048841,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 126,\n",
       "  'epsilom': 0.9986409130958881,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 127,\n",
       "  'epsilom': 0.9986309266867571,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 128,\n",
       "  'epsilom': 0.9986209403774903,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 129,\n",
       "  'epsilom': 0.9986109541680865,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 130,\n",
       "  'epsilom': 0.9986009680585449,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 131,\n",
       "  'epsilom': 0.9985909820488644,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 132,\n",
       "  'epsilom': 0.9985809961390439,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 133,\n",
       "  'epsilom': 0.9985710103290826,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 134,\n",
       "  'epsilom': 0.9985610246189793,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 135,\n",
       "  'epsilom': 0.9985510390087332,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 136,\n",
       "  'epsilom': 0.9985410534983432,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 137,\n",
       "  'epsilom': 0.9985310680878082,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 138,\n",
       "  'epsilom': 0.9985210827771274,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 139,\n",
       "  'epsilom': 0.9985110975662996,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 140,\n",
       "  'epsilom': 0.998501112455324,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 141,\n",
       "  'epsilom': 0.9984911274441995,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 142,\n",
       "  'epsilom': 0.9984811425329252,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 143,\n",
       "  'epsilom': 0.9984711577214999,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 144,\n",
       "  'epsilom': 0.9984611730099227,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 145,\n",
       "  'epsilom': 0.9984511883981926,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 146,\n",
       "  'epsilom': 0.9984412038863086,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 147,\n",
       "  'epsilom': 0.9984312194742698,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 148,\n",
       "  'epsilom': 0.9984212351620751,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 149,\n",
       "  'epsilom': 0.9984112509497236,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 150,\n",
       "  'epsilom': 0.9984012668372142,\n",
       "  'total_steps': 7,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 151,\n",
       "  'epsilom': 0.9983912828245459,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 152,\n",
       "  'epsilom': 0.9983812989117177,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 153,\n",
       "  'epsilom': 0.9983713150987286,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 154,\n",
       "  'epsilom': 0.9983613313855776,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 155,\n",
       "  'epsilom': 0.9983513477722638,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 156,\n",
       "  'epsilom': 0.9983413642587861,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 157,\n",
       "  'epsilom': 0.9983313808451435,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 158,\n",
       "  'epsilom': 0.9983213975313351,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 159,\n",
       "  'epsilom': 0.9983114143173598,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 160,\n",
       "  'epsilom': 0.9983014312032167,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 161,\n",
       "  'epsilom': 0.9982914481889047,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 162,\n",
       "  'epsilom': 0.9982814652744229,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 163,\n",
       "  'epsilom': 0.9982714824597702,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 164,\n",
       "  'epsilom': 0.9982614997449456,\n",
       "  'total_steps': 15,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 165,\n",
       "  'epsilom': 0.9982515171299482,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 166,\n",
       "  'epsilom': 0.9982415346147769,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 167,\n",
       "  'epsilom': 0.9982315521994308,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 168,\n",
       "  'epsilom': 0.9982215698839089,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 169,\n",
       "  'epsilom': 0.99821158766821,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 170,\n",
       "  'epsilom': 0.9982016055523334,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 171,\n",
       "  'epsilom': 0.9981916235362779,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 172,\n",
       "  'epsilom': 0.9981816416200425,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 173,\n",
       "  'epsilom': 0.9981716598036263,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 174,\n",
       "  'epsilom': 0.9981616780870284,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 175,\n",
       "  'epsilom': 0.9981516964702476,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 176,\n",
       "  'epsilom': 0.998141714953283,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 177,\n",
       "  'epsilom': 0.9981317335361335,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 178,\n",
       "  'epsilom': 0.9981217522187982,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 179,\n",
       "  'epsilom': 0.998111771001276,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 180,\n",
       "  'epsilom': 0.998101789883566,\n",
       "  'total_steps': 5,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 181,\n",
       "  'epsilom': 0.9980918088656672,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 182,\n",
       "  'epsilom': 0.9980818279475786,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 183,\n",
       "  'epsilom': 0.9980718471292992,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 184,\n",
       "  'epsilom': 0.998061866410828,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 185,\n",
       "  'epsilom': 0.9980518857921639,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 186,\n",
       "  'epsilom': 0.9980419052733059,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 187,\n",
       "  'epsilom': 0.9980319248542533,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 188,\n",
       "  'epsilom': 0.9980219445350048,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 189,\n",
       "  'epsilom': 0.9980119643155595,\n",
       "  'total_steps': 9,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 190,\n",
       "  'epsilom': 0.9980019841959163,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 191,\n",
       "  'epsilom': 0.9979920041760745,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 192,\n",
       "  'epsilom': 0.9979820242560328,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 193,\n",
       "  'epsilom': 0.9979720444357902,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 194,\n",
       "  'epsilom': 0.9979620647153459,\n",
       "  'total_steps': 3,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 195,\n",
       "  'epsilom': 0.9979520850946988,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 196,\n",
       "  'epsilom': 0.9979421055738479,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 197,\n",
       "  'epsilom': 0.9979321261527921,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 198,\n",
       "  'epsilom': 0.9979221468315307,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 199,\n",
       "  'epsilom': 0.9979121676100624,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 200,\n",
       "  'epsilom': 0.9979021884883863,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 201,\n",
       "  'epsilom': 0.9978922094665015,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 202,\n",
       "  'epsilom': 0.9978822305444068,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 203,\n",
       "  'epsilom': 0.9978722517221015,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 204,\n",
       "  'epsilom': 0.9978622729995843,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 205,\n",
       "  'epsilom': 0.9978522943768543,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 206,\n",
       "  'epsilom': 0.9978423158539106,\n",
       "  'total_steps': 11,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 207,\n",
       "  'epsilom': 0.9978323374307521,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 208,\n",
       "  'epsilom': 0.9978223591073778,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 209,\n",
       "  'epsilom': 0.9978123808837868,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 210,\n",
       "  'epsilom': 0.997802402759978,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 211,\n",
       "  'epsilom': 0.9977924247359504,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 212,\n",
       "  'epsilom': 0.9977824468117031,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 213,\n",
       "  'epsilom': 0.997772468987235,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 214,\n",
       "  'epsilom': 0.9977624912625452,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 215,\n",
       "  'epsilom': 0.9977525136376326,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 216,\n",
       "  'epsilom': 0.9977425361124963,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 217,\n",
       "  'epsilom': 0.9977325586871352,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 218,\n",
       "  'epsilom': 0.9977225813615483,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 219,\n",
       "  'epsilom': 0.9977126041357348,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 220,\n",
       "  'epsilom': 0.9977026270096935,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 221,\n",
       "  'epsilom': 0.9976926499834234,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 222,\n",
       "  'epsilom': 0.9976826730569236,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 223,\n",
       "  'epsilom': 0.9976726962301931,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 224,\n",
       "  'epsilom': 0.9976627195032308,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 225,\n",
       "  'epsilom': 0.9976527428760358,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 226,\n",
       "  'epsilom': 0.997642766348607,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 227,\n",
       "  'epsilom': 0.9976327899209436,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 228,\n",
       "  'epsilom': 0.9976228135930445,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 229,\n",
       "  'epsilom': 0.9976128373649086,\n",
       "  'total_steps': 13,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 230,\n",
       "  'epsilom': 0.997602861236535,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 231,\n",
       "  'epsilom': 0.9975928852079227,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 232,\n",
       "  'epsilom': 0.9975829092790707,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 233,\n",
       "  'epsilom': 0.9975729334499779,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 234,\n",
       "  'epsilom': 0.9975629577206434,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 235,\n",
       "  'epsilom': 0.9975529820910662,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 236,\n",
       "  'epsilom': 0.9975430065612454,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 237,\n",
       "  'epsilom': 0.9975330311311799,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 238,\n",
       "  'epsilom': 0.9975230558008686,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 239,\n",
       "  'epsilom': 0.9975130805703106,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 240,\n",
       "  'epsilom': 0.9975031054395049,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 241,\n",
       "  'epsilom': 0.9974931304084506,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 242,\n",
       "  'epsilom': 0.9974831554771465,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 243,\n",
       "  'epsilom': 0.9974731806455918,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 244,\n",
       "  'epsilom': 0.9974632059137853,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 245,\n",
       "  'epsilom': 0.9974532312817262,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 246,\n",
       "  'epsilom': 0.9974432567494135,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 247,\n",
       "  'epsilom': 0.997433282316846,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 248,\n",
       "  'epsilom': 0.9974233079840229,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 249,\n",
       "  'epsilom': 0.9974133337509431,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 250,\n",
       "  'epsilom': 0.9974033596176056,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 251,\n",
       "  'epsilom': 0.9973933855840095,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 252,\n",
       "  'epsilom': 0.9973834116501537,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 253,\n",
       "  'epsilom': 0.9973734378160372,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 254,\n",
       "  'epsilom': 0.997363464081659,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 255,\n",
       "  'epsilom': 0.9973534904470183,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 256,\n",
       "  'epsilom': 0.9973435169121139,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 257,\n",
       "  'epsilom': 0.9973335434769448,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 258,\n",
       "  'epsilom': 0.9973235701415101,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 259,\n",
       "  'epsilom': 0.9973135969058087,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 260,\n",
       "  'epsilom': 0.9973036237698396,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 261,\n",
       "  'epsilom': 0.997293650733602,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 262,\n",
       "  'epsilom': 0.9972836777970947,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 263,\n",
       "  'epsilom': 0.9972737049603168,\n",
       "  'total_steps': 5,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 264,\n",
       "  'epsilom': 0.9972637322232671,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 265,\n",
       "  'epsilom': 0.997253759585945,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 266,\n",
       "  'epsilom': 0.9972437870483492,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 267,\n",
       "  'epsilom': 0.9972338146104787,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 268,\n",
       "  'epsilom': 0.9972238422723326,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 269,\n",
       "  'epsilom': 0.9972138700339099,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 270,\n",
       "  'epsilom': 0.9972038978952097,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 271,\n",
       "  'epsilom': 0.9971939258562308,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 272,\n",
       "  'epsilom': 0.9971839539169722,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 273,\n",
       "  'epsilom': 0.9971739820774331,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 274,\n",
       "  'epsilom': 0.9971640103376124,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 275,\n",
       "  'epsilom': 0.9971540386975091,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 276,\n",
       "  'epsilom': 0.9971440671571221,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 277,\n",
       "  'epsilom': 0.9971340957164506,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 278,\n",
       "  'epsilom': 0.9971241243754935,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 279,\n",
       "  'epsilom': 0.9971141531342498,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 280,\n",
       "  'epsilom': 0.9971041819927184,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 281,\n",
       "  'epsilom': 0.9970942109508986,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 282,\n",
       "  'epsilom': 0.9970842400087891,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 283,\n",
       "  'epsilom': 0.9970742691663891,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 284,\n",
       "  'epsilom': 0.9970642984236975,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 285,\n",
       "  'epsilom': 0.9970543277807133,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 286,\n",
       "  'epsilom': 0.9970443572374356,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 287,\n",
       "  'epsilom': 0.9970343867938632,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 288,\n",
       "  'epsilom': 0.9970244164499954,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 289,\n",
       "  'epsilom': 0.9970144462058309,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 290,\n",
       "  'epsilom': 0.9970044760613689,\n",
       "  'total_steps': 3,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 291,\n",
       "  'epsilom': 0.9969945060166083,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 292,\n",
       "  'epsilom': 0.9969845360715482,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 293,\n",
       "  'epsilom': 0.9969745662261875,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 294,\n",
       "  'epsilom': 0.9969645964805253,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 295,\n",
       "  'epsilom': 0.9969546268345605,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 296,\n",
       "  'epsilom': 0.9969446572882922,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 297,\n",
       "  'epsilom': 0.9969346878417193,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 298,\n",
       "  'epsilom': 0.996924718494841,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 299,\n",
       "  'epsilom': 0.9969147492476561,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 300,\n",
       "  'epsilom': 0.9969047801001637,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 301,\n",
       "  'epsilom': 0.9968948110523628,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 302,\n",
       "  'epsilom': 0.9968848421042523,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 303,\n",
       "  'epsilom': 0.9968748732558314,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 304,\n",
       "  'epsilom': 0.9968649045070989,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 305,\n",
       "  'epsilom': 0.9968549358580538,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 306,\n",
       "  'epsilom': 0.9968449673086953,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 307,\n",
       "  'epsilom': 0.9968349988590223,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 308,\n",
       "  'epsilom': 0.9968250305090337,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 309,\n",
       "  'epsilom': 0.9968150622587286,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 310,\n",
       "  'epsilom': 0.996805094108106,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 311,\n",
       "  'epsilom': 0.996795126057165,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 312,\n",
       "  'epsilom': 0.9967851581059045,\n",
       "  'total_steps': 15,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 313,\n",
       "  'epsilom': 0.9967751902543235,\n",
       "  'total_steps': 2,\n",
       "  'reward_1': 0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 314,\n",
       "  'epsilom': 0.9967652225024209,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 315,\n",
       "  'epsilom': 0.996755254850196,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 316,\n",
       "  'epsilom': 0.9967452872976476,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 317,\n",
       "  'epsilom': 0.9967353198447746,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 318,\n",
       "  'epsilom': 0.9967253524915762,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 319,\n",
       "  'epsilom': 0.9967153852380514,\n",
       "  'total_steps': 7,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 320,\n",
       "  'epsilom': 0.996705418084199,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 321,\n",
       "  'epsilom': 0.9966954510300182,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 322,\n",
       "  'epsilom': 0.9966854840755079,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 323,\n",
       "  'epsilom': 0.9966755172206673,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 324,\n",
       "  'epsilom': 0.9966655504654951,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 325,\n",
       "  'epsilom': 0.9966555838099905,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 326,\n",
       "  'epsilom': 0.9966456172541525,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 327,\n",
       "  'epsilom': 0.99663565079798,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 328,\n",
       "  'epsilom': 0.996625684441472,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 329,\n",
       "  'epsilom': 0.9966157181846277,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 330,\n",
       "  'epsilom': 0.9966057520274458,\n",
       "  'total_steps': 15,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 331,\n",
       "  'epsilom': 0.9965957859699256,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 332,\n",
       "  'epsilom': 0.996585820012066,\n",
       "  'total_steps': 2,\n",
       "  'reward_1': 0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 333,\n",
       "  'epsilom': 0.9965758541538658,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 334,\n",
       "  'epsilom': 0.9965658883953243,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 335,\n",
       "  'epsilom': 0.9965559227364404,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 336,\n",
       "  'epsilom': 0.9965459571772132,\n",
       "  'total_steps': 13,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 337,\n",
       "  'epsilom': 0.9965359917176414,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 338,\n",
       "  'epsilom': 0.9965260263577242,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 339,\n",
       "  'epsilom': 0.9965160610974607,\n",
       "  'total_steps': 15,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 340,\n",
       "  'epsilom': 0.9965060959368498,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 341,\n",
       "  'epsilom': 0.9964961308758905,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 342,\n",
       "  'epsilom': 0.9964861659145818,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 343,\n",
       "  'epsilom': 0.9964762010529228,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 344,\n",
       "  'epsilom': 0.9964662362909122,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 345,\n",
       "  'epsilom': 0.9964562716285493,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 346,\n",
       "  'epsilom': 0.996446307065833,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 347,\n",
       "  'epsilom': 0.9964363426027624,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 348,\n",
       "  'epsilom': 0.9964263782393364,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 349,\n",
       "  'epsilom': 0.9964164139755541,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 350,\n",
       "  'epsilom': 0.9964064498114145,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 351,\n",
       "  'epsilom': 0.9963964857469164,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 352,\n",
       "  'epsilom': 0.996386521782059,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 353,\n",
       "  'epsilom': 0.9963765579168412,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 354,\n",
       "  'epsilom': 0.996366594151262,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 355,\n",
       "  'epsilom': 0.9963566304853206,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 356,\n",
       "  'epsilom': 0.9963466669190159,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 357,\n",
       "  'epsilom': 0.9963367034523467,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 358,\n",
       "  'epsilom': 0.9963267400853122,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 359,\n",
       "  'epsilom': 0.9963167768179114,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 360,\n",
       "  'epsilom': 0.9963068136501433,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 361,\n",
       "  'epsilom': 0.9962968505820068,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 362,\n",
       "  'epsilom': 0.996286887613501,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 363,\n",
       "  'epsilom': 0.9962769247446249,\n",
       "  'total_steps': 7,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 364,\n",
       "  'epsilom': 0.9962669619753776,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 365,\n",
       "  'epsilom': 0.9962569993057578,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 366,\n",
       "  'epsilom': 0.9962470367357649,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 367,\n",
       "  'epsilom': 0.9962370742653975,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 368,\n",
       "  'epsilom': 0.996227111894655,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 369,\n",
       "  'epsilom': 0.996217149623536,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 370,\n",
       "  'epsilom': 0.9962071874520398,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 371,\n",
       "  'epsilom': 0.9961972253801654,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 372,\n",
       "  'epsilom': 0.9961872634079116,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 373,\n",
       "  'epsilom': 0.9961773015352776,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 374,\n",
       "  'epsilom': 0.9961673397622623,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 375,\n",
       "  'epsilom': 0.9961573780888647,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 376,\n",
       "  'epsilom': 0.9961474165150839,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 377,\n",
       "  'epsilom': 0.9961374550409188,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 378,\n",
       "  'epsilom': 0.9961274936663684,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 379,\n",
       "  'epsilom': 0.9961175323914319,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 380,\n",
       "  'epsilom': 0.996107571216108,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 381,\n",
       "  'epsilom': 0.9960976101403959,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 382,\n",
       "  'epsilom': 0.9960876491642945,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 383,\n",
       "  'epsilom': 0.9960776882878029,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 384,\n",
       "  'epsilom': 0.99606772751092,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 385,\n",
       "  'epsilom': 0.9960577668336449,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 386,\n",
       "  'epsilom': 0.9960478062559766,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 387,\n",
       "  'epsilom': 0.996037845777914,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 388,\n",
       "  'epsilom': 0.9960278853994563,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 389,\n",
       "  'epsilom': 0.9960179251206024,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 390,\n",
       "  'epsilom': 0.9960079649413512,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 391,\n",
       "  'epsilom': 0.9959980048617019,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 392,\n",
       "  'epsilom': 0.9959880448816533,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 393,\n",
       "  'epsilom': 0.9959780850012045,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 394,\n",
       "  'epsilom': 0.9959681252203546,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 395,\n",
       "  'epsilom': 0.9959581655391024,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 396,\n",
       "  'epsilom': 0.995948205957447,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 397,\n",
       "  'epsilom': 0.9959382464753875,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 398,\n",
       "  'epsilom': 0.9959282870929228,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 399,\n",
       "  'epsilom': 0.995918327810052,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 400,\n",
       "  'epsilom': 0.9959083686267739,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 401,\n",
       "  'epsilom': 0.9958984095430877,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 402,\n",
       "  'epsilom': 0.9958884505589923,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 403,\n",
       "  'epsilom': 0.9958784916744868,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 404,\n",
       "  'epsilom': 0.9958685328895701,\n",
       "  'total_steps': 5,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 405,\n",
       "  'epsilom': 0.9958585742042413,\n",
       "  'total_steps': 7,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 406,\n",
       "  'epsilom': 0.9958486156184992,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 407,\n",
       "  'epsilom': 0.9958386571323431,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 408,\n",
       "  'epsilom': 0.9958286987457718,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 409,\n",
       "  'epsilom': 0.9958187404587844,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 410,\n",
       "  'epsilom': 0.9958087822713798,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 411,\n",
       "  'epsilom': 0.9957988241835571,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 412,\n",
       "  'epsilom': 0.9957888661953154,\n",
       "  'total_steps': 9,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 413,\n",
       "  'epsilom': 0.9957789083066535,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 414,\n",
       "  'epsilom': 0.9957689505175705,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 415,\n",
       "  'epsilom': 0.9957589928280653,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 416,\n",
       "  'epsilom': 0.9957490352381371,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 417,\n",
       "  'epsilom': 0.9957390777477847,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 418,\n",
       "  'epsilom': 0.9957291203570072,\n",
       "  'total_steps': 3,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 419,\n",
       "  'epsilom': 0.9957191630658037,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 420,\n",
       "  'epsilom': 0.995709205874173,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 421,\n",
       "  'epsilom': 0.9956992487821144,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 422,\n",
       "  'epsilom': 0.9956892917896266,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 423,\n",
       "  'epsilom': 0.9956793348967088,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 424,\n",
       "  'epsilom': 0.9956693781033599,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 425,\n",
       "  'epsilom': 0.9956594214095789,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 426,\n",
       "  'epsilom': 0.9956494648153648,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 427,\n",
       "  'epsilom': 0.9956395083207167,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 428,\n",
       "  'epsilom': 0.9956295519256335,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 429,\n",
       "  'epsilom': 0.9956195956301143,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 430,\n",
       "  'epsilom': 0.995609639434158,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 431,\n",
       "  'epsilom': 0.9955996833377637,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 432,\n",
       "  'epsilom': 0.9955897273409304,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 433,\n",
       "  'epsilom': 0.9955797714436571,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 434,\n",
       "  'epsilom': 0.9955698156459427,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 435,\n",
       "  'epsilom': 0.9955598599477863,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 436,\n",
       "  'epsilom': 0.9955499043491869,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 437,\n",
       "  'epsilom': 0.9955399488501434,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 438,\n",
       "  'epsilom': 0.995529993450655,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 439,\n",
       "  'epsilom': 0.9955200381507205,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 440,\n",
       "  'epsilom': 0.995510082950339,\n",
       "  'total_steps': 5,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 441,\n",
       "  'epsilom': 0.9955001278495096,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 442,\n",
       "  'epsilom': 0.9954901728482312,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 443,\n",
       "  'epsilom': 0.9954802179465028,\n",
       "  'total_steps': 11,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 444,\n",
       "  'epsilom': 0.9954702631443233,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 445,\n",
       "  'epsilom': 0.9954603084416919,\n",
       "  'total_steps': 11,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 446,\n",
       "  'epsilom': 0.9954503538386075,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 447,\n",
       "  'epsilom': 0.9954403993350691,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 448,\n",
       "  'epsilom': 0.9954304449310758,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 449,\n",
       "  'epsilom': 0.9954204906266265,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 450,\n",
       "  'epsilom': 0.9954105364217203,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 451,\n",
       "  'epsilom': 0.9954005823163561,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 452,\n",
       "  'epsilom': 0.9953906283105329,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 453,\n",
       "  'epsilom': 0.9953806744042498,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 454,\n",
       "  'epsilom': 0.9953707205975059,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 455,\n",
       "  'epsilom': 0.9953607668903,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 456,\n",
       "  'epsilom': 0.9953508132826311,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 457,\n",
       "  'epsilom': 0.9953408597744983,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 458,\n",
       "  'epsilom': 0.9953309063659006,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 459,\n",
       "  'epsilom': 0.995320953056837,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 460,\n",
       "  'epsilom': 0.9953109998473064,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 461,\n",
       "  'epsilom': 0.995301046737308,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 462,\n",
       "  'epsilom': 0.9952910937268407,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 463,\n",
       "  'epsilom': 0.9952811408159035,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 464,\n",
       "  'epsilom': 0.9952711880044953,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 465,\n",
       "  'epsilom': 0.9952612352926153,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 466,\n",
       "  'epsilom': 0.9952512826802624,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 467,\n",
       "  'epsilom': 0.9952413301674357,\n",
       "  'total_steps': 11,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 468,\n",
       "  'epsilom': 0.9952313777541341,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 469,\n",
       "  'epsilom': 0.9952214254403565,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 470,\n",
       "  'epsilom': 0.9952114732261022,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 471,\n",
       "  'epsilom': 0.99520152111137,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 472,\n",
       "  'epsilom': 0.9951915690961589,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 473,\n",
       "  'epsilom': 0.995181617180468,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 474,\n",
       "  'epsilom': 0.9951716653642962,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 475,\n",
       "  'epsilom': 0.9951617136476426,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 476,\n",
       "  'epsilom': 0.9951517620305061,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 477,\n",
       "  'epsilom': 0.9951418105128859,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 478,\n",
       "  'epsilom': 0.9951318590947807,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 479,\n",
       "  'epsilom': 0.9951219077761898,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 480,\n",
       "  'epsilom': 0.995111956557112,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 481,\n",
       "  'epsilom': 0.9951020054375466,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 482,\n",
       "  'epsilom': 0.9950920544174923,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 483,\n",
       "  'epsilom': 0.9950821034969481,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 484,\n",
       "  'epsilom': 0.9950721526759132,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 485,\n",
       "  'epsilom': 0.9950622019543864,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 486,\n",
       "  'epsilom': 0.995052251332367,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 487,\n",
       "  'epsilom': 0.9950423008098537,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 488,\n",
       "  'epsilom': 0.9950323503868457,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 489,\n",
       "  'epsilom': 0.9950224000633419,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 490,\n",
       "  'epsilom': 0.9950124498393412,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 491,\n",
       "  'epsilom': 0.9950024997148429,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 492,\n",
       "  'epsilom': 0.9949925496898457,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 493,\n",
       "  'epsilom': 0.9949825997643489,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 494,\n",
       "  'epsilom': 0.9949726499383513,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 495,\n",
       "  'epsilom': 0.994962700211852,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 496,\n",
       "  'epsilom': 0.9949527505848499,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 497,\n",
       "  'epsilom': 0.9949428010573441,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 498,\n",
       "  'epsilom': 0.9949328516293335,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 499,\n",
       "  'epsilom': 0.9949229023008173,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 500,\n",
       "  'epsilom': 0.9949129530717943,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 501,\n",
       "  'epsilom': 0.9949030039422636,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 502,\n",
       "  'epsilom': 0.9948930549122242,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 503,\n",
       "  'epsilom': 0.9948831059816752,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 504,\n",
       "  'epsilom': 0.9948731571506154,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 505,\n",
       "  'epsilom': 0.994863208419044,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 506,\n",
       "  'epsilom': 0.9948532597869598,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 507,\n",
       "  'epsilom': 0.994843311254362,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 508,\n",
       "  'epsilom': 0.9948333628212495,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 509,\n",
       "  'epsilom': 0.9948234144876212,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 510,\n",
       "  'epsilom': 0.9948134662534764,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 511,\n",
       "  'epsilom': 0.994803518118814,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 512,\n",
       "  'epsilom': 0.9947935700836328,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 513,\n",
       "  'epsilom': 0.994783622147932,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 514,\n",
       "  'epsilom': 0.9947736743117106,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 515,\n",
       "  'epsilom': 0.9947637265749675,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 516,\n",
       "  'epsilom': 0.9947537789377018,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 517,\n",
       "  'epsilom': 0.9947438313999124,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 518,\n",
       "  'epsilom': 0.9947338839615985,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 519,\n",
       "  'epsilom': 0.9947239366227589,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 520,\n",
       "  'epsilom': 0.9947139893833927,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 521,\n",
       "  'epsilom': 0.994704042243499,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 522,\n",
       "  'epsilom': 0.9946940952030766,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 523,\n",
       "  'epsilom': 0.9946841482621246,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 524,\n",
       "  'epsilom': 0.994674201420642,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 525,\n",
       "  'epsilom': 0.9946642546786278,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 526,\n",
       "  'epsilom': 0.9946543080360811,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 527,\n",
       "  'epsilom': 0.9946443614930008,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 528,\n",
       "  'epsilom': 0.994634415049386,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 529,\n",
       "  'epsilom': 0.9946244687052356,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 530,\n",
       "  'epsilom': 0.9946145224605486,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 531,\n",
       "  'epsilom': 0.9946045763153241,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 532,\n",
       "  'epsilom': 0.994594630269561,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 533,\n",
       "  'epsilom': 0.9945846843232583,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 534,\n",
       "  'epsilom': 0.9945747384764151,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 535,\n",
       "  'epsilom': 0.9945647927290304,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 536,\n",
       "  'epsilom': 0.9945548470811032,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 537,\n",
       "  'epsilom': 0.9945449015326324,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 538,\n",
       "  'epsilom': 0.9945349560836171,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 539,\n",
       "  'epsilom': 0.9945250107340563,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 540,\n",
       "  'epsilom': 0.994515065483949,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 541,\n",
       "  'epsilom': 0.9945051203332942,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 542,\n",
       "  'epsilom': 0.9944951752820909,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 543,\n",
       "  'epsilom': 0.9944852303303381,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 544,\n",
       "  'epsilom': 0.9944752854780349,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 545,\n",
       "  'epsilom': 0.9944653407251801,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 546,\n",
       "  'epsilom': 0.9944553960717729,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 547,\n",
       "  'epsilom': 0.9944454515178123,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 548,\n",
       "  'epsilom': 0.9944355070632971,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 549,\n",
       "  'epsilom': 0.9944255627082265,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 550,\n",
       "  'epsilom': 0.9944156184525994,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 551,\n",
       "  'epsilom': 0.9944056742964149,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 552,\n",
       "  'epsilom': 0.994395730239672,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 553,\n",
       "  'epsilom': 0.9943857862823696,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 554,\n",
       "  'epsilom': 0.9943758424245068,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 555,\n",
       "  'epsilom': 0.9943658986660826,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 556,\n",
       "  'epsilom': 0.994355955007096,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 557,\n",
       "  'epsilom': 0.994346011447546,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 558,\n",
       "  'epsilom': 0.9943360679874316,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 559,\n",
       "  'epsilom': 0.9943261246267517,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 560,\n",
       "  'epsilom': 0.9943161813655055,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 561,\n",
       "  'epsilom': 0.9943062382036919,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 562,\n",
       "  'epsilom': 0.9942962951413099,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 563,\n",
       "  'epsilom': 0.9942863521783586,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 564,\n",
       "  'epsilom': 0.9942764093148369,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 565,\n",
       "  'epsilom': 0.9942664665507438,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 566,\n",
       "  'epsilom': 0.9942565238860783,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 567,\n",
       "  'epsilom': 0.9942465813208395,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 568,\n",
       "  'epsilom': 0.9942366388550263,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 569,\n",
       "  'epsilom': 0.9942266964886378,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 570,\n",
       "  'epsilom': 0.994216754221673,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 571,\n",
       "  'epsilom': 0.9942068120541309,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 572,\n",
       "  'epsilom': 0.9941968699860103,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 573,\n",
       "  'epsilom': 0.9941869280173105,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 574,\n",
       "  'epsilom': 0.9941769861480303,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 575,\n",
       "  'epsilom': 0.9941670443781688,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 576,\n",
       "  'epsilom': 0.9941571027077251,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 577,\n",
       "  'epsilom': 0.994147161136698,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 578,\n",
       "  'epsilom': 0.9941372196650866,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 579,\n",
       "  'epsilom': 0.99412727829289,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 580,\n",
       "  'epsilom': 0.9941173370201072,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 581,\n",
       "  'epsilom': 0.994107395846737,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 582,\n",
       "  'epsilom': 0.9940974547727786,\n",
       "  'total_steps': 9,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 583,\n",
       "  'epsilom': 0.9940875137982309,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 584,\n",
       "  'epsilom': 0.994077572923093,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 585,\n",
       "  'epsilom': 0.9940676321473638,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 586,\n",
       "  'epsilom': 0.9940576914710424,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 587,\n",
       "  'epsilom': 0.9940477508941278,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 588,\n",
       "  'epsilom': 0.9940378104166189,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 589,\n",
       "  'epsilom': 0.9940278700385148,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 590,\n",
       "  'epsilom': 0.9940179297598144,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 591,\n",
       "  'epsilom': 0.9940079895805168,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 592,\n",
       "  'epsilom': 0.9939980495006211,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 593,\n",
       "  'epsilom': 0.9939881095201262,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 594,\n",
       "  'epsilom': 0.993978169639031,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 595,\n",
       "  'epsilom': 0.9939682298573346,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 596,\n",
       "  'epsilom': 0.993958290175036,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 597,\n",
       "  'epsilom': 0.9939483505921343,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 598,\n",
       "  'epsilom': 0.9939384111086284,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 599,\n",
       "  'epsilom': 0.9939284717245173,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 600,\n",
       "  'epsilom': 0.9939185324398001,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 601,\n",
       "  'epsilom': 0.9939085932544758,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 602,\n",
       "  'epsilom': 0.9938986541685433,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 603,\n",
       "  'epsilom': 0.9938887151820016,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 604,\n",
       "  'epsilom': 0.9938787762948499,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 605,\n",
       "  'epsilom': 0.993868837507087,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 606,\n",
       "  'epsilom': 0.9938588988187119,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 607,\n",
       "  'epsilom': 0.9938489602297238,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 608,\n",
       "  'epsilom': 0.9938390217401215,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 609,\n",
       "  'epsilom': 0.9938290833499042,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 610,\n",
       "  'epsilom': 0.9938191450590708,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 611,\n",
       "  'epsilom': 0.9938092068676202,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 612,\n",
       "  'epsilom': 0.9937992687755516,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 613,\n",
       "  'epsilom': 0.9937893307828639,\n",
       "  'total_steps': 15,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 614,\n",
       "  'epsilom': 0.9937793928895561,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 615,\n",
       "  'epsilom': 0.9937694550956272,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 616,\n",
       "  'epsilom': 0.9937595174010763,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 617,\n",
       "  'epsilom': 0.9937495798059023,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 618,\n",
       "  'epsilom': 0.9937396423101043,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 619,\n",
       "  'epsilom': 0.9937297049136812,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 620,\n",
       "  'epsilom': 0.993719767616632,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 621,\n",
       "  'epsilom': 0.9937098304189559,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 622,\n",
       "  'epsilom': 0.9936998933206518,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 623,\n",
       "  'epsilom': 0.9936899563217186,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 624,\n",
       "  'epsilom': 0.9936800194221554,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 625,\n",
       "  'epsilom': 0.9936700826219613,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 626,\n",
       "  'epsilom': 0.9936601459211352,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 627,\n",
       "  'epsilom': 0.993650209319676,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 628,\n",
       "  'epsilom': 0.9936402728175828,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 629,\n",
       "  'epsilom': 0.9936303364148547,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 630,\n",
       "  'epsilom': 0.9936204001114906,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 631,\n",
       "  'epsilom': 0.9936104639074895,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 632,\n",
       "  'epsilom': 0.9936005278028505,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 633,\n",
       "  'epsilom': 0.9935905917975725,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 634,\n",
       "  'epsilom': 0.9935806558916546,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 635,\n",
       "  'epsilom': 0.9935707200850957,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 636,\n",
       "  'epsilom': 0.993560784377895,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 637,\n",
       "  'epsilom': 0.9935508487700513,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 638,\n",
       "  'epsilom': 0.9935409132615637,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 639,\n",
       "  'epsilom': 0.9935309778524312,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 640,\n",
       "  'epsilom': 0.9935210425426527,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 641,\n",
       "  'epsilom': 0.9935111073322274,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 642,\n",
       "  'epsilom': 0.9935011722211541,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 643,\n",
       "  'epsilom': 0.9934912372094319,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 644,\n",
       "  'epsilom': 0.9934813022970599,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 645,\n",
       "  'epsilom': 0.993471367484037,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 646,\n",
       "  'epsilom': 0.9934614327703621,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 647,\n",
       "  'epsilom': 0.9934514981560345,\n",
       "  'total_steps': 2,\n",
       "  'reward_1': 0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 648,\n",
       "  'epsilom': 0.993441563641053,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 649,\n",
       "  'epsilom': 0.9934316292254166,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 650,\n",
       "  'epsilom': 0.9934216949091244,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 651,\n",
       "  'epsilom': 0.9934117606921753,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 652,\n",
       "  'epsilom': 0.9934018265745684,\n",
       "  'total_steps': 3,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 653,\n",
       "  'epsilom': 0.9933918925563028,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 654,\n",
       "  'epsilom': 0.9933819586373772,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 655,\n",
       "  'epsilom': 0.9933720248177909,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 656,\n",
       "  'epsilom': 0.9933620910975427,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 657,\n",
       "  'epsilom': 0.9933521574766317,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 658,\n",
       "  'epsilom': 0.993342223955057,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 659,\n",
       "  'epsilom': 0.9933322905328175,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 660,\n",
       "  'epsilom': 0.9933223572099121,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 661,\n",
       "  'epsilom': 0.9933124239863401,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 662,\n",
       "  'epsilom': 0.9933024908621003,\n",
       "  'total_steps': 2,\n",
       "  'reward_1': 0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 663,\n",
       "  'epsilom': 0.9932925578371917,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 664,\n",
       "  'epsilom': 0.9932826249116133,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 665,\n",
       "  'epsilom': 0.9932726920853643,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 666,\n",
       "  'epsilom': 0.9932627593584434,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 667,\n",
       "  'epsilom': 0.9932528267308499,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 668,\n",
       "  'epsilom': 0.9932428942025826,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 669,\n",
       "  'epsilom': 0.9932329617736406,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 670,\n",
       "  'epsilom': 0.993223029444023,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 671,\n",
       "  'epsilom': 0.9932130972137285,\n",
       "  'total_steps': 2,\n",
       "  'reward_1': 0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 672,\n",
       "  'epsilom': 0.9932031650827564,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 673,\n",
       "  'epsilom': 0.9931932330511056,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 674,\n",
       "  'epsilom': 0.9931833011187752,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 675,\n",
       "  'epsilom': 0.993173369285764,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 676,\n",
       "  'epsilom': 0.9931634375520713,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 677,\n",
       "  'epsilom': 0.9931535059176958,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 678,\n",
       "  'epsilom': 0.9931435743826367,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 679,\n",
       "  'epsilom': 0.9931336429468929,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 680,\n",
       "  'epsilom': 0.9931237116104634,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 681,\n",
       "  'epsilom': 0.9931137803733474,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 682,\n",
       "  'epsilom': 0.9931038492355437,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 683,\n",
       "  'epsilom': 0.9930939181970514,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 684,\n",
       "  'epsilom': 0.9930839872578695,\n",
       "  'total_steps': 3,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 685,\n",
       "  'epsilom': 0.993074056417997,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 686,\n",
       "  'epsilom': 0.9930641256774329,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 687,\n",
       "  'epsilom': 0.9930541950361761,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 688,\n",
       "  'epsilom': 0.9930442644942258,\n",
       "  'total_steps': 7,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 689,\n",
       "  'epsilom': 0.9930343340515809,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 690,\n",
       "  'epsilom': 0.9930244037082404,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 691,\n",
       "  'epsilom': 0.9930144734642034,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 692,\n",
       "  'epsilom': 0.9930045433194687,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 693,\n",
       "  'epsilom': 0.9929946132740356,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 694,\n",
       "  'epsilom': 0.9929846833279029,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 695,\n",
       "  'epsilom': 0.9929747534810697,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 696,\n",
       "  'epsilom': 0.9929648237335349,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 697,\n",
       "  'epsilom': 0.9929548940852976,\n",
       "  'total_steps': 7,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 698,\n",
       "  'epsilom': 0.9929449645363567,\n",
       "  'total_steps': 13,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 699,\n",
       "  'epsilom': 0.9929350350867114,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 700,\n",
       "  'epsilom': 0.9929251057363606,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 701,\n",
       "  'epsilom': 0.9929151764853033,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 702,\n",
       "  'epsilom': 0.9929052473335385,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 703,\n",
       "  'epsilom': 0.9928953182810651,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 704,\n",
       "  'epsilom': 0.9928853893278824,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 705,\n",
       "  'epsilom': 0.9928754604739891,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 706,\n",
       "  'epsilom': 0.9928655317193844,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 707,\n",
       "  'epsilom': 0.9928556030640673,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 708,\n",
       "  'epsilom': 0.9928456745080367,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 709,\n",
       "  'epsilom': 0.9928357460512917,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 710,\n",
       "  'epsilom': 0.9928258176938312,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 711,\n",
       "  'epsilom': 0.9928158894356542,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 712,\n",
       "  'epsilom': 0.9928059612767599,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 713,\n",
       "  'epsilom': 0.9927960332171472,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 714,\n",
       "  'epsilom': 0.992786105256815,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 715,\n",
       "  'epsilom': 0.9927761773957625,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 716,\n",
       "  'epsilom': 0.9927662496339886,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 717,\n",
       "  'epsilom': 0.9927563219714923,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 718,\n",
       "  'epsilom': 0.9927463944082726,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 719,\n",
       "  'epsilom': 0.9927364669443286,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 720,\n",
       "  'epsilom': 0.9927265395796592,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 721,\n",
       "  'epsilom': 0.9927166123142634,\n",
       "  'total_steps': 7,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 722,\n",
       "  'epsilom': 0.9927066851481403,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': -100.0,\n",
       "  'reward_total': -100.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 723,\n",
       "  'epsilom': 0.9926967580812889,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 724,\n",
       "  'epsilom': 0.9926868311137081,\n",
       "  'total_steps': 11,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 725,\n",
       "  'epsilom': 0.992676904245397,\n",
       "  'total_steps': 2,\n",
       "  'reward_1': 0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 726,\n",
       "  'epsilom': 0.9926669774763546,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 727,\n",
       "  'epsilom': 0.9926570508065798,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 728,\n",
       "  'epsilom': 0.9926471242360718,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 729,\n",
       "  'epsilom': 0.9926371977648295,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 730,\n",
       "  'epsilom': 0.9926272713928519,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 731,\n",
       "  'epsilom': 0.992617345120138,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 732,\n",
       "  'epsilom': 0.9926074189466868,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 733,\n",
       "  'epsilom': 0.9925974928724974,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 734,\n",
       "  'epsilom': 0.9925875668975688,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 735,\n",
       "  'epsilom': 0.9925776410218998,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 736,\n",
       "  'epsilom': 0.9925677152454897,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 737,\n",
       "  'epsilom': 0.9925577895683373,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 738,\n",
       "  'epsilom': 0.9925478639904417,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 739,\n",
       "  'epsilom': 0.9925379385118018,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 740,\n",
       "  'epsilom': 0.9925280131324168,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 741,\n",
       "  'epsilom': 0.9925180878522855,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 742,\n",
       "  'epsilom': 0.992508162671407,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 743,\n",
       "  'epsilom': 0.9924982375897803,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 744,\n",
       "  'epsilom': 0.9924883126074044,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 745,\n",
       "  'epsilom': 0.9924783877242784,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 746,\n",
       "  'epsilom': 0.9924684629404013,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 747,\n",
       "  'epsilom': 0.9924585382557719,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 748,\n",
       "  'epsilom': 0.9924486136703894,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 749,\n",
       "  'epsilom': 0.9924386891842527,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 750,\n",
       "  'epsilom': 0.9924287647973609,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 751,\n",
       "  'epsilom': 0.992418840509713,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 752,\n",
       "  'epsilom': 0.9924089163213079,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 753,\n",
       "  'epsilom': 0.9923989922321448,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 754,\n",
       "  'epsilom': 0.9923890682422225,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 755,\n",
       "  'epsilom': 0.9923791443515402,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 756,\n",
       "  'epsilom': 0.9923692205600967,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 757,\n",
       "  'epsilom': 0.9923592968678911,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 758,\n",
       "  'epsilom': 0.9923493732749226,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 759,\n",
       "  'epsilom': 0.9923394497811898,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 760,\n",
       "  'epsilom': 0.992329526386692,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 761,\n",
       "  'epsilom': 0.9923196030914282,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 762,\n",
       "  'epsilom': 0.9923096798953973,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 763,\n",
       "  'epsilom': 0.9922997567985984,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 764,\n",
       "  'epsilom': 0.9922898338010304,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 765,\n",
       "  'epsilom': 0.9922799109026924,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 766,\n",
       "  'epsilom': 0.9922699881035835,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 767,\n",
       "  'epsilom': 0.9922600654037025,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 768,\n",
       "  'epsilom': 0.9922501428030485,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 769,\n",
       "  'epsilom': 0.9922402203016205,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 770,\n",
       "  'epsilom': 0.9922302978994175,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 771,\n",
       "  'epsilom': 0.9922203755964386,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 772,\n",
       "  'epsilom': 0.9922104533926827,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 773,\n",
       "  'epsilom': 0.9922005312881488,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 774,\n",
       "  'epsilom': 0.992190609282836,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 775,\n",
       "  'epsilom': 0.9921806873767431,\n",
       "  'total_steps': 2,\n",
       "  'reward_1': 0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 776,\n",
       "  'epsilom': 0.9921707655698694,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 777,\n",
       "  'epsilom': 0.9921608438622137,\n",
       "  'total_steps': 9,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 778,\n",
       "  'epsilom': 0.9921509222537751,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 779,\n",
       "  'epsilom': 0.9921410007445526,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 780,\n",
       "  'epsilom': 0.9921310793345451,\n",
       "  'total_steps': 9,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 781,\n",
       "  'epsilom': 0.9921211580237519,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 782,\n",
       "  'epsilom': 0.9921112368121717,\n",
       "  'total_steps': 5,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 783,\n",
       "  'epsilom': 0.9921013156998036,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 784,\n",
       "  'epsilom': 0.9920913946866466,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 785,\n",
       "  'epsilom': 0.9920814737726998,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 786,\n",
       "  'epsilom': 0.9920715529579621,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 787,\n",
       "  'epsilom': 0.9920616322424326,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 788,\n",
       "  'epsilom': 0.9920517116261102,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 789,\n",
       "  'epsilom': 0.9920417911089939,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 790,\n",
       "  'epsilom': 0.9920318706910829,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 791,\n",
       "  'epsilom': 0.9920219503723761,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 792,\n",
       "  'epsilom': 0.9920120301528724,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 793,\n",
       "  'epsilom': 0.992002110032571,\n",
       "  'total_steps': 5,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 794,\n",
       "  'epsilom': 0.9919921900114708,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 795,\n",
       "  'epsilom': 0.9919822700895707,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 796,\n",
       "  'epsilom': 0.9919723502668699,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 797,\n",
       "  'epsilom': 0.9919624305433673,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 798,\n",
       "  'epsilom': 0.9919525109190619,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 799,\n",
       "  'epsilom': 0.9919425913939528,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 800,\n",
       "  'epsilom': 0.9919326719680389,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 801,\n",
       "  'epsilom': 0.9919227526413192,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 802,\n",
       "  'epsilom': 0.9919128334137929,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 803,\n",
       "  'epsilom': 0.9919029142854587,\n",
       "  'total_steps': 5,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 804,\n",
       "  'epsilom': 0.9918929952563159,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 805,\n",
       "  'epsilom': 0.9918830763263634,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 806,\n",
       "  'epsilom': 0.9918731574956002,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 807,\n",
       "  'epsilom': 0.9918632387640253,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 808,\n",
       "  'epsilom': 0.9918533201316376,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 809,\n",
       "  'epsilom': 0.9918434015984363,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 810,\n",
       "  'epsilom': 0.9918334831644203,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 811,\n",
       "  'epsilom': 0.9918235648295888,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 812,\n",
       "  'epsilom': 0.9918136465939406,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 813,\n",
       "  'epsilom': 0.9918037284574747,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 814,\n",
       "  'epsilom': 0.9917938104201901,\n",
       "  'total_steps': 7,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 815,\n",
       "  'epsilom': 0.991783892482086,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 816,\n",
       "  'epsilom': 0.9917739746431612,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 817,\n",
       "  'epsilom': 0.9917640569034148,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 818,\n",
       "  'epsilom': 0.9917541392628458,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 819,\n",
       "  'epsilom': 0.9917442217214533,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 820,\n",
       "  'epsilom': 0.9917343042792361,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 821,\n",
       "  'epsilom': 0.9917243869361934,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 822,\n",
       "  'epsilom': 0.991714469692324,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 823,\n",
       "  'epsilom': 0.9917045525476271,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 824,\n",
       "  'epsilom': 0.9916946355021017,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 825,\n",
       "  'epsilom': 0.9916847185557467,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 826,\n",
       "  'epsilom': 0.9916748017085611,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 827,\n",
       "  'epsilom': 0.9916648849605441,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 828,\n",
       "  'epsilom': 0.9916549683116945,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 829,\n",
       "  'epsilom': 0.9916450517620115,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 830,\n",
       "  'epsilom': 0.9916351353114938,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 831,\n",
       "  'epsilom': 0.9916252189601408,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 832,\n",
       "  'epsilom': 0.9916153027079512,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 833,\n",
       "  'epsilom': 0.9916053865549241,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 834,\n",
       "  'epsilom': 0.9915954705010587,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 835,\n",
       "  'epsilom': 0.9915855545463537,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 836,\n",
       "  'epsilom': 0.9915756386908082,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 837,\n",
       "  'epsilom': 0.9915657229344214,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 838,\n",
       "  'epsilom': 0.9915558072771921,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 839,\n",
       "  'epsilom': 0.9915458917191193,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 840,\n",
       "  'epsilom': 0.9915359762602022,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 841,\n",
       "  'epsilom': 0.9915260609004396,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 842,\n",
       "  'epsilom': 0.9915161456398306,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 843,\n",
       "  'epsilom': 0.9915062304783743,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 844,\n",
       "  'epsilom': 0.9914963154160695,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 845,\n",
       "  'epsilom': 0.9914864004529154,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 846,\n",
       "  'epsilom': 0.9914764855889109,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 847,\n",
       "  'epsilom': 0.9914665708240551,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 848,\n",
       "  'epsilom': 0.9914566561583469,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 849,\n",
       "  'epsilom': 0.9914467415917854,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 850,\n",
       "  'epsilom': 0.9914368271243695,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 851,\n",
       "  'epsilom': 0.9914269127560983,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 852,\n",
       "  'epsilom': 0.9914169984869707,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 853,\n",
       "  'epsilom': 0.9914070843169859,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 854,\n",
       "  'epsilom': 0.9913971702461427,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 855,\n",
       "  'epsilom': 0.9913872562744402,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 856,\n",
       "  'epsilom': 0.9913773424018776,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 857,\n",
       "  'epsilom': 0.9913674286284536,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 858,\n",
       "  'epsilom': 0.9913575149541674,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 859,\n",
       "  'epsilom': 0.9913476013790179,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 860,\n",
       "  'epsilom': 0.9913376879030041,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 861,\n",
       "  'epsilom': 0.9913277745261252,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 862,\n",
       "  'epsilom': 0.99131786124838,\n",
       "  'total_steps': 2,\n",
       "  'reward_1': 0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 863,\n",
       "  'epsilom': 0.9913079480697675,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 864,\n",
       "  'epsilom': 0.9912980349902869,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 865,\n",
       "  'epsilom': 0.991288122009937,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 866,\n",
       "  'epsilom': 0.9912782091287169,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 867,\n",
       "  'epsilom': 0.9912682963466256,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 868,\n",
       "  'epsilom': 0.9912583836636621,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 869,\n",
       "  'epsilom': 0.9912484710798255,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 870,\n",
       "  'epsilom': 0.9912385585951148,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 871,\n",
       "  'epsilom': 0.9912286462095289,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 872,\n",
       "  'epsilom': 0.9912187339230668,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 873,\n",
       "  'epsilom': 0.9912088217357277,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 874,\n",
       "  'epsilom': 0.9911989096475103,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2001000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 875,\n",
       "  'epsilom': 0.991188997658414,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 876,\n",
       "  'epsilom': 0.9911790857684374,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 877,\n",
       "  'epsilom': 0.9911691739775798,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 878,\n",
       "  'epsilom': 0.9911592622858401,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1200000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 879,\n",
       "  'epsilom': 0.9911493506932172,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 880,\n",
       "  'epsilom': 0.9911394391997103,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 881,\n",
       "  'epsilom': 0.9911295278053183,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 882,\n",
       "  'epsilom': 0.9911196165100402,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 883,\n",
       "  'epsilom': 0.9911097053138752,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 884,\n",
       "  'epsilom': 0.9910997942168221,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 885,\n",
       "  'epsilom': 0.99108988321888,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 886,\n",
       "  'epsilom': 0.9910799723200479,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 887,\n",
       "  'epsilom': 0.9910700615203247,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 888,\n",
       "  'epsilom': 0.9910601508197096,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 889,\n",
       "  'epsilom': 0.9910502402182014,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 890,\n",
       "  'epsilom': 0.9910403297157993,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 891,\n",
       "  'epsilom': 0.9910304193125021,\n",
       "  'total_steps': 3,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 892,\n",
       "  'epsilom': 0.9910205090083091,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 893,\n",
       "  'epsilom': 0.9910105988032191,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 894,\n",
       "  'epsilom': 0.9910006886972311,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 100.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 895,\n",
       "  'epsilom': 0.9909907786903442,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 896,\n",
       "  'epsilom': 0.9909808687825574,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 897,\n",
       "  'epsilom': 0.9909709589738697,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 898,\n",
       "  'epsilom': 0.99096104926428,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 899,\n",
       "  'epsilom': 0.9909511396537873,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 900,\n",
       "  'epsilom': 0.9909412301423909,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 901,\n",
       "  'epsilom': 0.9909313207300895,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 902,\n",
       "  'epsilom': 0.9909214114168823,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 903,\n",
       "  'epsilom': 0.9909115022027681,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 904,\n",
       "  'epsilom': 0.9909015930877462,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 905,\n",
       "  'epsilom': 0.9908916840718154,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 906,\n",
       "  'epsilom': 0.9908817751549747,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 907,\n",
       "  'epsilom': 0.9908718663372231,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 908,\n",
       "  'epsilom': 0.9908619576185598,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 909,\n",
       "  'epsilom': 0.9908520489989836,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 910,\n",
       "  'epsilom': 0.9908421404784936,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 911,\n",
       "  'epsilom': 0.9908322320570889,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 912,\n",
       "  'epsilom': 0.9908223237347684,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 913,\n",
       "  'epsilom': 0.9908124155115311,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 914,\n",
       "  'epsilom': 0.9908025073873761,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 915,\n",
       "  'epsilom': 0.9907925993623022,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 916,\n",
       "  'epsilom': 0.9907826914363087,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 917,\n",
       "  'epsilom': 0.9907727836093944,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 918,\n",
       "  'epsilom': 0.9907628758815583,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 919,\n",
       "  'epsilom': 0.9907529682527996,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 920,\n",
       "  'epsilom': 0.9907430607231171,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 921,\n",
       "  'epsilom': 0.99073315329251,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 922,\n",
       "  'epsilom': 0.9907232459609772,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 923,\n",
       "  'epsilom': 0.9907133387285176,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 924,\n",
       "  'epsilom': 0.9907034315951304,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 925,\n",
       "  'epsilom': 0.9906935245608145,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 926,\n",
       "  'epsilom': 0.9906836176255689,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 927,\n",
       "  'epsilom': 0.9906737107893927,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 928,\n",
       "  'epsilom': 0.9906638040522848,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 929,\n",
       "  'epsilom': 0.9906538974142444,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 930,\n",
       "  'epsilom': 0.9906439908752702,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 931,\n",
       "  'epsilom': 0.9906340844353615,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 932,\n",
       "  'epsilom': 0.9906241780945172,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 933,\n",
       "  'epsilom': 0.9906142718527363,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 934,\n",
       "  'epsilom': 0.9906043657100179,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 935,\n",
       "  'epsilom': 0.9905944596663608,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 936,\n",
       "  'epsilom': 0.9905845537217642,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0201000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 937,\n",
       "  'epsilom': 0.9905746478762271,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 938,\n",
       "  'epsilom': 0.9905647421297483,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 939,\n",
       "  'epsilom': 0.9905548364823271,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 940,\n",
       "  'epsilom': 0.9905449309339623,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 941,\n",
       "  'epsilom': 0.990535025484653,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 942,\n",
       "  'epsilom': 0.9905251201343982,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 943,\n",
       "  'epsilom': 0.9905152148831969,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 944,\n",
       "  'epsilom': 0.9905053097310481,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 945,\n",
       "  'epsilom': 0.9904954046779508,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0210000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 946,\n",
       "  'epsilom': 0.9904854997239041,\n",
       "  'total_steps': 7,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 947,\n",
       "  'epsilom': 0.9904755948689069,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1002000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 948,\n",
       "  'epsilom': 0.9904656901129583,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 949,\n",
       "  'epsilom': 0.9904557854560572,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 950,\n",
       "  'epsilom': 0.9904458808982026,\n",
       "  'total_steps': 13,\n",
       "  'reward_1': 100.0,\n",
       "  'reward_2': 100.0,\n",
       "  'reward_total': 200.0,\n",
       "  'final_state': '0000021',\n",
       "  'did_reach_terminal': True},\n",
       " {'episode': 951,\n",
       "  'epsilom': 0.9904359764393937,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 952,\n",
       "  'epsilom': 0.9904260720796294,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 953,\n",
       "  'epsilom': 0.9904161678189086,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 954,\n",
       "  'epsilom': 0.9904062636572305,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 955,\n",
       "  'epsilom': 0.9903963595945939,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 956,\n",
       "  'epsilom': 0.990386455630998,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 957,\n",
       "  'epsilom': 0.9903765517664418,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 958,\n",
       "  'epsilom': 0.9903666480009242,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 959,\n",
       "  'epsilom': 0.9903567443344442,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 960,\n",
       "  'epsilom': 0.9903468407670009,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1000200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 961,\n",
       "  'epsilom': 0.9903369372985932,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 962,\n",
       "  'epsilom': 0.9903270339292203,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 963,\n",
       "  'epsilom': 0.990317130658881,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000210',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 964,\n",
       "  'epsilom': 0.9903072274875745,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 965,\n",
       "  'epsilom': 0.9902973244152996,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002100',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 966,\n",
       "  'epsilom': 0.9902874214420555,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 967,\n",
       "  'epsilom': 0.9902775185678411,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 968,\n",
       "  'epsilom': 0.9902676157926554,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 969,\n",
       "  'epsilom': 0.9902577131164976,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 970,\n",
       "  'epsilom': 0.9902478105393665,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0012000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 971,\n",
       "  'epsilom': 0.9902379080612611,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 972,\n",
       "  'epsilom': 0.9902280056821805,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0200001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 973,\n",
       "  'epsilom': 0.9902181034021237,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000102',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 974,\n",
       "  'epsilom': 0.9902082012210897,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000201',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 975,\n",
       "  'epsilom': 0.9901982991390775,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 976,\n",
       "  'epsilom': 0.9901883971560862,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0102000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 977,\n",
       "  'epsilom': 0.9901784952721147,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 978,\n",
       "  'epsilom': 0.990168593487162,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 979,\n",
       "  'epsilom': 0.9901586918012272,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000120',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 980,\n",
       "  'epsilom': 0.9901487902143092,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0001020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 981,\n",
       "  'epsilom': 0.9901388887264071,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 982,\n",
       "  'epsilom': 0.9901289873375199,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2010000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 983,\n",
       "  'epsilom': 0.9901190860476465,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 984,\n",
       "  'epsilom': 0.9901091848567861,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0002001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 985,\n",
       "  'epsilom': 0.9900992837649376,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010002',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 986,\n",
       "  'epsilom': 0.9900893827721,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 987,\n",
       "  'epsilom': 0.9900794818782723,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 988,\n",
       "  'epsilom': 0.9900695810834536,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000001',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 989,\n",
       "  'epsilom': 0.9900596803876428,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2100000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 990,\n",
       "  'epsilom': 0.990049779790839,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 991,\n",
       "  'epsilom': 0.9900398792930412,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '1020000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 992,\n",
       "  'epsilom': 0.9900299788942483,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0100200',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 993,\n",
       "  'epsilom': 0.9900200785944594,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0021000',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 994,\n",
       "  'epsilom': 0.9900101783936734,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 995,\n",
       "  'epsilom': 0.9900002782918895,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '2000010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 996,\n",
       "  'epsilom': 0.9899903782891066,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0000012',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 997,\n",
       "  'epsilom': 0.9899804783853238,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0010020',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 998,\n",
       "  'epsilom': 0.9899705785805399,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0020010',\n",
       "  'did_reach_terminal': False},\n",
       " {'episode': 999,\n",
       "  'epsilom': 0.9899606788747541,\n",
       "  'total_steps': 16,\n",
       "  'reward_1': 0.0,\n",
       "  'reward_2': 0.0,\n",
       "  'reward_total': 0.0,\n",
       "  'final_state': '0120000',\n",
       "  'did_reach_terminal': False},\n",
       " ...]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main Loop\n",
    "\n",
    "# Empty init to keep variables in global scope\n",
    "Q = np.nan\n",
    "R = np.nan\n",
    "\n",
    "def perform_experiment():\n",
    "    global Q\n",
    "    global R\n",
    "    (Q, R) = initialize_tables(EXPERIMENT['num_agents'])\n",
    "    \n",
    "    epsilom = EXPERIMENT['epsilom']['initial_value']\n",
    "    results = []\n",
    "    \n",
    "    for current_episode in range(EXPERIMENT['num_episodes']):\n",
    "        episode_result = run_episode(epsilom)\n",
    "        results.append({'episode': current_episode, **episode_result})\n",
    "        epsilom = update_epsilom(epsilom)\n",
    "\n",
    "        # Progress report\n",
    "        if (current_episode%(EXPERIMENT['num_episodes']/10) == 0):\n",
    "            progress = current_episode/EXPERIMENT['num_episodes']\n",
    "            progress_string = '{:02d}%  '.format(int(progress*100))\n",
    "            print(progress_string, end='')\n",
    "    \n",
    "    return results\n",
    "\n",
    "perform_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00%  10%  20%  30%  40%  50%  60%  70%  80%  90%  "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did_reach_terminal</th>\n",
       "      <th>episode</th>\n",
       "      <th>epsilom</th>\n",
       "      <th>final_state</th>\n",
       "      <th>reward_1</th>\n",
       "      <th>reward_total</th>\n",
       "      <th>total_steps</th>\n",
       "      <th>rwd_1</th>\n",
       "      <th>rwd_tot</th>\n",
       "      <th>window_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>9.990000e-01</td>\n",
       "      <td>0100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>9.970020e-01</td>\n",
       "      <td>0001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>9.950080e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>9.930180e-01</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>9.910319e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>9.890499e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>9.870718e-01</td>\n",
       "      <td>0010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>9.850976e-01</td>\n",
       "      <td>0010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>9.831274e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>9.811612e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>9.791989e-01</td>\n",
       "      <td>0100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>9.772405e-01</td>\n",
       "      <td>0010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>9.752860e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>9.733354e-01</td>\n",
       "      <td>0010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>9.713887e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>9.694460e-01</td>\n",
       "      <td>0010000</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-14.285714</td>\n",
       "      <td>-14.285714</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>9.675071e-01</td>\n",
       "      <td>0000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>9.655721e-01</td>\n",
       "      <td>0010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>9.636409e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>9.617136e-01</td>\n",
       "      <td>0010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>9.597902e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>9.578706e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>9.559549e-01</td>\n",
       "      <td>0100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>9.540430e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>9.521349e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>9.502306e-01</td>\n",
       "      <td>0010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>9.483302e-01</td>\n",
       "      <td>0010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>9.464335e-01</td>\n",
       "      <td>0000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>9.445406e-01</td>\n",
       "      <td>0001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>9.426515e-01</td>\n",
       "      <td>0000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>True</td>\n",
       "      <td>9970</td>\n",
       "      <td>2.143197e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>True</td>\n",
       "      <td>9971</td>\n",
       "      <td>2.138911e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>True</td>\n",
       "      <td>9972</td>\n",
       "      <td>2.134633e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.973228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>True</td>\n",
       "      <td>9973</td>\n",
       "      <td>2.130364e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>True</td>\n",
       "      <td>9974</td>\n",
       "      <td>2.126103e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.973233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>True</td>\n",
       "      <td>9975</td>\n",
       "      <td>2.121851e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.973236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>True</td>\n",
       "      <td>9976</td>\n",
       "      <td>2.117607e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.973238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>True</td>\n",
       "      <td>9977</td>\n",
       "      <td>2.113372e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.973241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>True</td>\n",
       "      <td>9978</td>\n",
       "      <td>2.109145e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.973244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>True</td>\n",
       "      <td>9979</td>\n",
       "      <td>2.104927e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>True</td>\n",
       "      <td>9980</td>\n",
       "      <td>2.100717e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.973249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>True</td>\n",
       "      <td>9981</td>\n",
       "      <td>2.096515e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>True</td>\n",
       "      <td>9982</td>\n",
       "      <td>2.092322e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>True</td>\n",
       "      <td>9983</td>\n",
       "      <td>2.088138e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>True</td>\n",
       "      <td>9984</td>\n",
       "      <td>2.083962e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.973260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>True</td>\n",
       "      <td>9985</td>\n",
       "      <td>2.079794e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>True</td>\n",
       "      <td>9986</td>\n",
       "      <td>2.075634e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>True</td>\n",
       "      <td>9987</td>\n",
       "      <td>2.071483e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.973268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>True</td>\n",
       "      <td>9988</td>\n",
       "      <td>2.067340e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.973271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>True</td>\n",
       "      <td>9989</td>\n",
       "      <td>2.063205e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.973273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>True</td>\n",
       "      <td>9990</td>\n",
       "      <td>2.059079e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>True</td>\n",
       "      <td>9991</td>\n",
       "      <td>2.054961e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.973279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>True</td>\n",
       "      <td>9992</td>\n",
       "      <td>2.050851e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.973281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>True</td>\n",
       "      <td>9993</td>\n",
       "      <td>2.046749e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.973284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>True</td>\n",
       "      <td>9994</td>\n",
       "      <td>2.042655e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>True</td>\n",
       "      <td>9995</td>\n",
       "      <td>2.038570e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>True</td>\n",
       "      <td>9996</td>\n",
       "      <td>2.034493e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>True</td>\n",
       "      <td>9997</td>\n",
       "      <td>2.030424e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.973295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>True</td>\n",
       "      <td>9998</td>\n",
       "      <td>2.026363e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.973297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>True</td>\n",
       "      <td>9999</td>\n",
       "      <td>2.022310e-09</td>\n",
       "      <td>0000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.973300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      did_reach_terminal  episode       epsilom final_state  reward_1  \\\n",
       "0                  False        0  9.990000e-01     0100000       0.0   \n",
       "1                  False        1  9.970020e-01     0001000       0.0   \n",
       "2                   True        2  9.950080e-01     0000001     100.0   \n",
       "3                  False        3  9.930180e-01     1000000       0.0   \n",
       "4                   True        4  9.910319e-01     0000001     100.0   \n",
       "5                   True        5  9.890499e-01     0000001     100.0   \n",
       "6                  False        6  9.870718e-01     0010000       0.0   \n",
       "7                  False        7  9.850976e-01     0010000       0.0   \n",
       "8                   True        8  9.831274e-01     0000001     100.0   \n",
       "9                   True        9  9.811612e-01     0000001     100.0   \n",
       "10                 False       10  9.791989e-01     0100000       0.0   \n",
       "11                 False       11  9.772405e-01     0010000       0.0   \n",
       "12                  True       12  9.752860e-01     0000001     100.0   \n",
       "13                 False       13  9.733354e-01     0010000       0.0   \n",
       "14                  True       14  9.713887e-01     0000001     100.0   \n",
       "15                 False       15  9.694460e-01     0010000    -100.0   \n",
       "16                 False       16  9.675071e-01     0000100       0.0   \n",
       "17                 False       17  9.655721e-01     0010000       0.0   \n",
       "18                  True       18  9.636409e-01     0000001     100.0   \n",
       "19                 False       19  9.617136e-01     0010000       0.0   \n",
       "20                  True       20  9.597902e-01     0000001     100.0   \n",
       "21                  True       21  9.578706e-01     0000001     100.0   \n",
       "22                 False       22  9.559549e-01     0100000       0.0   \n",
       "23                  True       23  9.540430e-01     0000001     100.0   \n",
       "24                  True       24  9.521349e-01     0000001     100.0   \n",
       "25                 False       25  9.502306e-01     0010000       0.0   \n",
       "26                 False       26  9.483302e-01     0010000       0.0   \n",
       "27                 False       27  9.464335e-01     0000010       0.0   \n",
       "28                 False       28  9.445406e-01     0001000       0.0   \n",
       "29                  True       29  9.426515e-01     0000001       0.0   \n",
       "...                  ...      ...           ...         ...       ...   \n",
       "9970                True     9970  2.143197e-09     0000001     100.0   \n",
       "9971                True     9971  2.138911e-09     0000001     100.0   \n",
       "9972                True     9972  2.134633e-09     0000001     100.0   \n",
       "9973                True     9973  2.130364e-09     0000001     100.0   \n",
       "9974                True     9974  2.126103e-09     0000001     100.0   \n",
       "9975                True     9975  2.121851e-09     0000001     100.0   \n",
       "9976                True     9976  2.117607e-09     0000001     100.0   \n",
       "9977                True     9977  2.113372e-09     0000001     100.0   \n",
       "9978                True     9978  2.109145e-09     0000001     100.0   \n",
       "9979                True     9979  2.104927e-09     0000001     100.0   \n",
       "9980                True     9980  2.100717e-09     0000001     100.0   \n",
       "9981                True     9981  2.096515e-09     0000001     100.0   \n",
       "9982                True     9982  2.092322e-09     0000001     100.0   \n",
       "9983                True     9983  2.088138e-09     0000001     100.0   \n",
       "9984                True     9984  2.083962e-09     0000001     100.0   \n",
       "9985                True     9985  2.079794e-09     0000001     100.0   \n",
       "9986                True     9986  2.075634e-09     0000001     100.0   \n",
       "9987                True     9987  2.071483e-09     0000001     100.0   \n",
       "9988                True     9988  2.067340e-09     0000001     100.0   \n",
       "9989                True     9989  2.063205e-09     0000001     100.0   \n",
       "9990                True     9990  2.059079e-09     0000001     100.0   \n",
       "9991                True     9991  2.054961e-09     0000001     100.0   \n",
       "9992                True     9992  2.050851e-09     0000001     100.0   \n",
       "9993                True     9993  2.046749e-09     0000001     100.0   \n",
       "9994                True     9994  2.042655e-09     0000001     100.0   \n",
       "9995                True     9995  2.038570e-09     0000001     100.0   \n",
       "9996                True     9996  2.034493e-09     0000001     100.0   \n",
       "9997                True     9997  2.030424e-09     0000001     100.0   \n",
       "9998                True     9998  2.026363e-09     0000001     100.0   \n",
       "9999                True     9999  2.022310e-09     0000001     100.0   \n",
       "\n",
       "      reward_total  total_steps      rwd_1    rwd_tot  window_%  \n",
       "0              0.0            7   0.000000   0.000000  0.000000  \n",
       "1              0.0            7   0.000000   0.000000  0.000000  \n",
       "2            100.0            2  50.000000  50.000000  0.333333  \n",
       "3              0.0            7   0.000000   0.000000  0.250000  \n",
       "4            100.0            4  25.000000  25.000000  0.400000  \n",
       "5            100.0            6  16.666667  16.666667  0.500000  \n",
       "6              0.0            7   0.000000   0.000000  0.428571  \n",
       "7              0.0            7   0.000000   0.000000  0.375000  \n",
       "8            100.0            5  20.000000  20.000000  0.444444  \n",
       "9            100.0            5  20.000000  20.000000  0.500000  \n",
       "10             0.0            7   0.000000   0.000000  0.454545  \n",
       "11             0.0            7   0.000000   0.000000  0.416667  \n",
       "12           100.0            7  14.285714  14.285714  0.461538  \n",
       "13             0.0            7   0.000000   0.000000  0.428571  \n",
       "14           100.0            6  16.666667  16.666667  0.466667  \n",
       "15          -100.0            7 -14.285714 -14.285714  0.437500  \n",
       "16             0.0            7   0.000000   0.000000  0.411765  \n",
       "17             0.0            7   0.000000   0.000000  0.388889  \n",
       "18           100.0            6  16.666667  16.666667  0.421053  \n",
       "19             0.0            7   0.000000   0.000000  0.400000  \n",
       "20           100.0            2  50.000000  50.000000  0.428571  \n",
       "21           100.0            3  33.333333  33.333333  0.454545  \n",
       "22             0.0            7   0.000000   0.000000  0.434783  \n",
       "23           100.0            2  50.000000  50.000000  0.458333  \n",
       "24           100.0            5  20.000000  20.000000  0.480000  \n",
       "25             0.0            7   0.000000   0.000000  0.461538  \n",
       "26             0.0            7   0.000000   0.000000  0.444444  \n",
       "27             0.0            7   0.000000   0.000000  0.428571  \n",
       "28             0.0            7   0.000000   0.000000  0.413793  \n",
       "29             0.0            4   0.000000   0.000000  0.433333  \n",
       "...            ...          ...        ...        ...       ...  \n",
       "9970         100.0            5  20.000000  20.000000  0.973222  \n",
       "9971         100.0            5  20.000000  20.000000  0.973225  \n",
       "9972         100.0            4  25.000000  25.000000  0.973228  \n",
       "9973         100.0            5  20.000000  20.000000  0.973230  \n",
       "9974         100.0            3  33.333333  33.333333  0.973233  \n",
       "9975         100.0            2  50.000000  50.000000  0.973236  \n",
       "9976         100.0            2  50.000000  50.000000  0.973238  \n",
       "9977         100.0            2  50.000000  50.000000  0.973241  \n",
       "9978         100.0            4  25.000000  25.000000  0.973244  \n",
       "9979         100.0            5  20.000000  20.000000  0.973246  \n",
       "9980         100.0            4  25.000000  25.000000  0.973249  \n",
       "9981         100.0            5  20.000000  20.000000  0.973252  \n",
       "9982         100.0            5  20.000000  20.000000  0.973255  \n",
       "9983         100.0            5  20.000000  20.000000  0.973257  \n",
       "9984         100.0            4  25.000000  25.000000  0.973260  \n",
       "9985         100.0            5  20.000000  20.000000  0.973263  \n",
       "9986         100.0            5  20.000000  20.000000  0.973265  \n",
       "9987         100.0            2  50.000000  50.000000  0.973268  \n",
       "9988         100.0            3  33.333333  33.333333  0.973271  \n",
       "9989         100.0            2  50.000000  50.000000  0.973273  \n",
       "9990         100.0            5  20.000000  20.000000  0.973276  \n",
       "9991         100.0            3  33.333333  33.333333  0.973279  \n",
       "9992         100.0            2  50.000000  50.000000  0.973281  \n",
       "9993         100.0            3  33.333333  33.333333  0.973284  \n",
       "9994         100.0            5  20.000000  20.000000  0.973287  \n",
       "9995         100.0            5  20.000000  20.000000  0.973289  \n",
       "9996         100.0            5  20.000000  20.000000  0.973292  \n",
       "9997         100.0            2  50.000000  50.000000  0.973295  \n",
       "9998         100.0            5  20.000000  20.000000  0.973297  \n",
       "9999         100.0            2  50.000000  50.000000  0.973300  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_results(experiment_results):\n",
    "    df = process_results(experiment_results)\n",
    "    plt.figure(1); \n",
    "    df['window_%'].plot(); \n",
    "    df['epsilom'].plot()\n",
    "    \n",
    "#     plt.figure(2); df[df['did_reach_terminal'] == True].plot.scatter(x='episode', y='total_steps')\n",
    "    plt.figure(2); df.plot.scatter(x='episode', y='total_steps')\n",
    "    return df\n",
    "\n",
    "def process_results(experiment_results):\n",
    "    df = pd.DataFrame.from_records(experiment_results)\n",
    "    for agent_id in get_agent_ids():\n",
    "        agent_id = str(agent_id)\n",
    "        df['rwd_'+agent_id] = df['reward_'+agent_id]/df['total_steps']\n",
    "    df['rwd_tot'] = df['reward_total']/df['total_steps']\n",
    "    df['window_%'] = df['did_reach_terminal'].cumsum()/(df['episode']+1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# test_input = perform_experiment()\n",
    "show_results(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000100</th>\n",
       "      <th>0000010</th>\n",
       "      <th>0001000</th>\n",
       "      <th>0000001</th>\n",
       "      <th>1000000</th>\n",
       "      <th>0100000</th>\n",
       "      <th>0010000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000100</th>\n",
       "      <td>50.0</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000010</th>\n",
       "      <td>50.0</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.499823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.00005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0100000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.499992</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010000</th>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.499998</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0000100    0000010    0001000  0000001    1000000    0100000  0010000\n",
       "state                                                                         \n",
       "0000100     50.0  100.00000        NaN      NaN        NaN        NaN     25.0\n",
       "0000010     50.0  100.00000        NaN    200.0        NaN        NaN      NaN\n",
       "0001000      NaN        NaN  12.499823      NaN        NaN        NaN     25.0\n",
       "0000001      NaN   -0.00005        NaN    200.0        NaN        NaN      NaN\n",
       "1000000      NaN        NaN        NaN      NaN  12.500000        NaN     25.0\n",
       "0100000      NaN        NaN        NaN      NaN        NaN  12.499992     25.0\n",
       "0010000     50.0        NaN  12.500000      NaN  12.499998  12.500000     25.0"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location: 30 => (4, 2)\n",
      "location: (4, 2) => 30\n"
     ]
    }
   ],
   "source": [
    "def location_int_to_tuple(location):\n",
    "    if location >= BOARD_SIZE[0]*BOARD_SIZE[1]:\n",
    "        raise ValueError('location outside maze')\n",
    "    row = int(location/BOARD_WIDTH)\n",
    "    col = int(location%BOARD_WIDTH)\n",
    "    return (row, col)\n",
    "\n",
    "print('location: {} => {}'.format(30, location_int_to_tuple(30)))\n",
    "\n",
    "def location_tuple_to_int(location):\n",
    "    (row, col) = location\n",
    "    location_int = (row*BOARD_WIDTH+col)\n",
    "    if location_int >= BOARD_SIZE[0]*BOARD_SIZE[1]:\n",
    "        raise ValueError('location outside maze')\n",
    "    return location_int\n",
    "\n",
    "print('location: {} => {}'.format((4,2), location_tuple_to_int((4,2))))\n",
    "\n",
    "\n",
    "def get_future_position_for_action(previous_location, action):\n",
    "    (current_row, current_col) = location_int_to_tuple(previous_location)\n",
    "    \n",
    "    if (action == ACTION.UP):\n",
    "        (next_row, next_col) = (current_row-1, current_col)\n",
    "    elif (action == ACTION.RIGHT):\n",
    "        (next_row, next_col) = (current_row, current_col+1)\n",
    "    elif (action == ACTION.DOWN):\n",
    "        (next_row, next_col) = (current_row+1, current_col)\n",
    "    elif (action == ACTION.LEFT):\n",
    "        (next_row, next_col) = (current_row, current_col-1)\n",
    "    \n",
    "#     If out of bounds, remain in the same place.\n",
    "    if (\n",
    "        next_row < 0 \n",
    "        or next_row >= BOARD_HEIGHT \n",
    "        or next_col < 0 \n",
    "        or next_col >= BOARD_WIDTH\n",
    "    ):\n",
    "        (next_row, next_col) = (current_row, current_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r = generate_reward_matrix(1, 1)\n",
    "c = '0000001'\n",
    "n = ['0000001', '0000010']\n",
    "max(test_r.loc[c, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0001000</th>\n",
       "      <th>0000100</th>\n",
       "      <th>1000000</th>\n",
       "      <th>0010000</th>\n",
       "      <th>0000010</th>\n",
       "      <th>0100000</th>\n",
       "      <th>0000001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001000</th>\n",
       "      <td>12.499999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>49.999997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.999999</td>\n",
       "      <td>99.999995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.499999</td>\n",
       "      <td>24.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010000</th>\n",
       "      <td>12.499999</td>\n",
       "      <td>49.999997</td>\n",
       "      <td>12.499999</td>\n",
       "      <td>24.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.499999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000010</th>\n",
       "      <td>NaN</td>\n",
       "      <td>49.999997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.999995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0100000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.499999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.999992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.999979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0001000    0000100    1000000    0010000    0000010    0100000  \\\n",
       "state                                                                       \n",
       "0001000  12.499999        NaN        NaN  24.999999        NaN        NaN   \n",
       "0000100        NaN  49.999997        NaN  24.999999  99.999995        NaN   \n",
       "1000000        NaN        NaN  12.499999  24.999999        NaN        NaN   \n",
       "0010000  12.499999  49.999997  12.499999  24.999999        NaN  12.499999   \n",
       "0000010        NaN  49.999997        NaN        NaN  99.999995        NaN   \n",
       "0100000        NaN        NaN        NaN  24.999999        NaN  12.499999   \n",
       "0000001        NaN        NaN        NaN        NaN  99.999992        NaN   \n",
       "\n",
       "            0000001  \n",
       "state                \n",
       "0001000         NaN  \n",
       "0000100         NaN  \n",
       "1000000         NaN  \n",
       "0010000         NaN  \n",
       "0000010  199.999989  \n",
       "0100000         NaN  \n",
       "0000001  199.999979  "
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
